{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "618e6028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import cvxpy as cp\n",
    "from scipy import sparse as sp\n",
    "import scipy.special as sps\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import math\n",
    "\n",
    "from src.problems.utils import sample_data_for_group\n",
    "from src.problems.problems import compute_producer_optimal_solution, _compute_consumer_optimal_solution_cvar_relaxed_base, _compute_consumer_optimal_solution_cvar\n",
    "from src.problems.gradient_problem import compute_consumer_optimal_solution_cvar_grad, compute_consumer_optimal_with_augmented_lagrangian_cvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6e875cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_consumer_optimal_solution_cvar_relaxed_topk_rounding(\n",
    "    allocations: np.ndarray,\n",
    "    k_rec: int,\n",
    ") -> tuple[float, np.ndarray]:\n",
    "    idxs = allocations.argsort(axis=1)[:, -k_rec:]\n",
    "    alls = np.zeros_like(allocations)\n",
    "    alls[np.arange(allocations.shape[0])[:, None], idxs] = 1\n",
    "\n",
    "    return alls\n",
    "\n",
    "def _compute_consumer_optimal_solution_cvar_relaxed_naive_rounding(\n",
    "    allocations: np.ndarray,\n",
    ") -> tuple[float, np.ndarray]:\n",
    "    alls = allocations.round().astype(int)\n",
    "\n",
    "    return alls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c85e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(\"../../data/amazon_predictions.npy\", \"rb\") as f:\n",
    "    REL_MATRIX = np.load(f)\n",
    "\n",
    "with open(\"../../data/amazon_user_groups.json\", \"r\") as f:\n",
    "    GROUPS_MAP = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72c5b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CONSUMERS = 300\n",
    "N_PRODUCERS = 300\n",
    "ALPHA = 0.5\n",
    "GAMMA = 0.5\n",
    "GROUP_KEY = \"usage_group\"\n",
    "K_REC = 10\n",
    "SOLVER = cp.GUROBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b38ce9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perc_prod_below_threshold(\n",
    "    allocation: np.ndarray,\n",
    "    threshold: float,\n",
    ") -> float:\n",
    "    producer_allocations = allocation.sum(axis=0)\n",
    "    num_of_producers_below_threshold = np.sum(producer_allocations < threshold)\n",
    "    return num_of_producers_below_threshold / len(producer_allocations)\n",
    "\n",
    "def compute_mean_prod_below_threshold(\n",
    "    allocation: np.ndarray,\n",
    "    threshold: float,\n",
    ") -> float:\n",
    "    producer_allocations = allocation.sum(axis=0)\n",
    "    return np.mean(math.ceil(threshold) - producer_allocations[producer_allocations < threshold])\n",
    "\n",
    "def compute_mean_consumer_utility(\n",
    "    allocation: np.ndarray,\n",
    "    rel_matrix: np.ndarray,\n",
    ") -> float:\n",
    "    return (allocation * rel_matrix).sum() / allocation.sum()\n",
    "\n",
    "def compute_perc_cons_above_threshold(\n",
    "    allocation: np.ndarray,\n",
    "    k_rec: int\n",
    ") -> float:\n",
    "    consumer_allocations = allocation.sum(axis=1)\n",
    "    num_of_consumers_above_threshold = np.sum(consumer_allocations > k_rec)\n",
    "    return num_of_consumers_above_threshold / len(consumer_allocations)\n",
    "\n",
    "def compute_perc_cons_below_threshold(\n",
    "    allocation: np.ndarray,\n",
    "    k_rec: int\n",
    ") -> float:\n",
    "    consumer_allocations = allocation.sum(axis=1)\n",
    "    num_of_consumers_below_threshold = np.sum(consumer_allocations < k_rec)\n",
    "    return num_of_consumers_below_threshold / len(consumer_allocations)\n",
    "\n",
    "def compute_mean_cons_above_threshold(\n",
    "    allocation: np.ndarray,\n",
    "    k_rec: int\n",
    ") -> float:\n",
    "    consumer_allocations = allocation.sum(axis=1)\n",
    "    return np.mean(k_rec - consumer_allocations[consumer_allocations > k_rec])\n",
    "\n",
    "\n",
    "def compute_mean_cons_below_threshold(\n",
    "    allocation: np.ndarray,\n",
    "    k_rec: int\n",
    ") -> float:\n",
    "    consumer_allocations = allocation.sum(axis=1)\n",
    "    return np.mean(k_rec - consumer_allocations[consumer_allocations < k_rec])\n",
    "\n",
    "def compute_std_between_groups(allocations: np.ndarray, group_assignments: np.ndarray) -> float:\n",
    "    unique_groups, group_indices = np.unique(group_assignments, return_inverse=True)\n",
    "    num_groups = len(unique_groups)\n",
    "    group_masks = [group_indices == i for i in range(num_groups)]\n",
    "    group_sizes = np.array([mask.sum() for mask in group_masks])\n",
    "\n",
    "    means = []\n",
    "    for mask, size in zip(group_masks, group_sizes):\n",
    "        group_alloc = allocations[mask]\n",
    "        mean = np.mean(group_alloc.sum(axis=0))\n",
    "        means.append(mean)\n",
    "\n",
    "    return np.std(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ae532f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:105: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:109: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:113: SyntaxWarning: invalid escape sequence '\\#'\n",
      "<>:117: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:121: SyntaxWarning: invalid escape sequence '\\#'\n",
      "<>:125: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:129: SyntaxWarning: invalid escape sequence '\\#'\n",
      "<>:133: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:105: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:109: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:113: SyntaxWarning: invalid escape sequence '\\#'\n",
      "<>:117: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:121: SyntaxWarning: invalid escape sequence '\\#'\n",
      "<>:125: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:129: SyntaxWarning: invalid escape sequence '\\#'\n",
      "<>:133: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/669903939.py:105: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  stats[\"$\\mathbb{E}[{U_{C}}]$_\" + method] = compute_mean_consumer_utility(\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/669903939.py:109: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  stats[\"$\\sigma(\\mathbb{E}[U_{G}])$_\" + method] = compute_std_between_groups(\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/669903939.py:113: SyntaxWarning: invalid escape sequence '\\#'\n",
      "  stats[\"$\\#(U_{P} < U_{P\\min})/N_{P}$_\" + method] = compute_perc_prod_below_threshold(\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/669903939.py:117: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  stats[\"$\\sum(V - U_{P})/N_{P^{b}}$_\" + method] = compute_mean_prod_below_threshold(\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/669903939.py:121: SyntaxWarning: invalid escape sequence '\\#'\n",
      "  stats[\"$\\#(A_{C} > k)/N_{C}$_\" + method] = compute_perc_cons_above_threshold(\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/669903939.py:125: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  stats[\"$\\sum(A_{C} - k)/N_{A_{c}^{a}}$_\" + method] = compute_mean_cons_above_threshold(\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/669903939.py:129: SyntaxWarning: invalid escape sequence '\\#'\n",
      "  stats[\"$\\#(A_{C} < k)/N_{C}$_\" + method] = compute_perc_cons_below_threshold(\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/669903939.py:133: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  stats[\"$\\sum(k - A_{C})/N_{A_{c}^{b}}$_\" + method] = compute_mean_cons_below_threshold(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for size 100\n",
      "Running for k_rec 5\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dominykas.seputis/github/msc-thesis/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/dominykas.seputis/github/msc-thesis/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/dominykas.seputis/github/msc-thesis/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Running for k_rec 10\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Running for k_rec 25\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 0 1]]\n",
      "[[0 1 1 ... 0 0 1]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 1 0 1]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 1 ... 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for size in [100]:\n",
    "    print(f\"Running for size {size}\")\n",
    "    for k_rec in [5, 10, 25]:\n",
    "        print(f\"Running for k_rec {k_rec}\")\n",
    "        for run in range(3):\n",
    "            rel_matrix_sampled, consumer_ids, group_assignments = sample_data_for_group(\n",
    "                n_consumers=size,\n",
    "                n_producers=size,\n",
    "                groups_map=GROUPS_MAP,\n",
    "                group_key=GROUP_KEY,\n",
    "                data=REL_MATRIX,\n",
    "                naive_sampling=True,\n",
    "                seed=run,\n",
    "            )\n",
    "            producer_max_min_utility, _ = compute_producer_optimal_solution(\n",
    "                rel_matrix=rel_matrix_sampled,\n",
    "                k_rec=k_rec,\n",
    "                solver=SOLVER,\n",
    "            )\n",
    "            start_time = time()\n",
    "            _, optimal_allocation = _compute_consumer_optimal_solution_cvar(\n",
    "                rel_matrix=rel_matrix_sampled,\n",
    "                k_rec=k_rec,\n",
    "                producer_max_min_utility=producer_max_min_utility,\n",
    "                gamma=GAMMA,\n",
    "                group_assignments=group_assignments,\n",
    "                alpha=ALPHA,\n",
    "                solver=SOLVER,\n",
    "            )\n",
    "            optimal_time = time() - start_time\n",
    "\n",
    "            start_time = time()\n",
    "            _, _base_cvar_allocation = _compute_consumer_optimal_solution_cvar_relaxed_base(\n",
    "                rel_matrix=rel_matrix_sampled,\n",
    "                k_rec=k_rec,\n",
    "                producer_max_min_utility=producer_max_min_utility,\n",
    "                gamma=GAMMA,\n",
    "                group_assignments=group_assignments,\n",
    "                alpha=ALPHA,\n",
    "                solver=SOLVER,\n",
    "            )\n",
    "            relaxed_time = time() - start_time\n",
    "\n",
    "            rounded_cvar_allocation = _compute_consumer_optimal_solution_cvar_relaxed_naive_rounding(\n",
    "                allocations=_base_cvar_allocation,\n",
    "            )\n",
    "            topk_cvar_allocation = _compute_consumer_optimal_solution_cvar_relaxed_topk_rounding(\n",
    "                allocations=_base_cvar_allocation,\n",
    "                k_rec=k_rec,\n",
    "            )\n",
    "\n",
    "            start_time = time()\n",
    "            _base_cvar_grad_allocations, _ = compute_consumer_optimal_solution_cvar_grad(\n",
    "                rel_matrix=rel_matrix_sampled,\n",
    "                k_rec=k_rec,\n",
    "                producer_max_min_utility=producer_max_min_utility,\n",
    "                gamma=GAMMA,\n",
    "                group_assignments=group_assignments,\n",
    "                alpha=ALPHA,\n",
    "                hidden_dim=size * 2,\n",
    "                max_epochs=30000,\n",
    "                verbose=False,\n",
    "                max_patience=30,\n",
    "                patience_delta=1e-2\n",
    "            )\n",
    "            grad_time = time() - start_time\n",
    "\n",
    "            rounded_cvar_grad_allocation = _compute_consumer_optimal_solution_cvar_relaxed_naive_rounding(\n",
    "                allocations=_base_cvar_grad_allocations,\n",
    "            )\n",
    "            topk_cvar_grad_allocation = _compute_consumer_optimal_solution_cvar_relaxed_topk_rounding(\n",
    "                allocations=_base_cvar_grad_allocations,\n",
    "                k_rec=k_rec,\n",
    "            )\n",
    "\n",
    "            start_time = time()\n",
    "            _base_cvar_lang_allocation  = compute_consumer_optimal_with_augmented_lagrangian_cvar(\n",
    "                k_rec=k_rec,\n",
    "                rel_matrix=rel_matrix_sampled,\n",
    "                producer_max_min_utility=producer_max_min_utility,\n",
    "                gamma=GAMMA,\n",
    "                group_assignments=group_assignments,\n",
    "                alpha_cvar=ALPHA,\n",
    "                verbose=False,\n",
    "                max_epochs=40000,\n",
    "            )\n",
    "            lang_time = time() - start_time\n",
    "            rounded_cvar_lang_allocation = _compute_consumer_optimal_solution_cvar_relaxed_naive_rounding(\n",
    "                allocations=_base_cvar_lang_allocation,\n",
    "            )\n",
    "            print(rounded_cvar_lang_allocation)\n",
    "            topk_cvar_lang_allocation = _compute_consumer_optimal_solution_cvar_relaxed_topk_rounding(\n",
    "                allocations=_base_cvar_lang_allocation,\n",
    "                k_rec=k_rec,\n",
    "            )\n",
    "\n",
    "\n",
    "            stats = {}\n",
    "            for allocation, method in zip(\n",
    "                [optimal_allocation, rounded_cvar_allocation, topk_cvar_allocation, rounded_cvar_grad_allocation, topk_cvar_grad_allocation, rounded_cvar_lang_allocation, topk_cvar_lang_allocation],\n",
    "                [\"Baseline\", \"LP Round\", \"LP TopK\", \"Grad Round\", \"Grad TopK\", \"Lang Round\", \"Lang TopK\"]\n",
    "            ):\n",
    "                stats[\"$\\mathbb{E}[{U_{C}}]$_\" + method] = compute_mean_consumer_utility(\n",
    "                    allocation=allocation,\n",
    "                    rel_matrix=rel_matrix_sampled,\n",
    "                )\n",
    "                stats[\"$\\sigma(\\mathbb{E}[U_{G}])$_\" + method] = compute_std_between_groups(\n",
    "                    allocations=allocation,\n",
    "                    group_assignments=group_assignments,\n",
    "                )\n",
    "                stats[\"$\\#(U_{P} < U_{P\\min})/N_{P}$_\" + method] = compute_perc_prod_below_threshold(\n",
    "                    allocation=allocation,\n",
    "                    threshold=producer_max_min_utility * GAMMA,\n",
    "                )\n",
    "                stats[\"$\\sum(V - U_{P})/N_{P^{b}}$_\" + method] = compute_mean_prod_below_threshold(\n",
    "                    allocation=allocation,\n",
    "                    threshold=producer_max_min_utility * GAMMA,\n",
    "                )\n",
    "                stats[\"$\\#(A_{C} > k)/N_{C}$_\" + method] = compute_perc_cons_above_threshold(\n",
    "                    allocation=allocation,\n",
    "                    k_rec=k_rec,\n",
    "                )\n",
    "                stats[\"$\\sum(A_{C} - k)/N_{A_{c}^{a}}$_\" + method] = compute_mean_cons_above_threshold(\n",
    "                    allocation=allocation,\n",
    "                    k_rec=k_rec,\n",
    "                )\n",
    "                stats[\"$\\#(A_{C} < k)/N_{C}$_\" + method] = compute_perc_cons_below_threshold(\n",
    "                    allocation=allocation,\n",
    "                    k_rec=k_rec,\n",
    "                )\n",
    "                stats[\"$\\sum(k - A_{C})/N_{A_{c}^{b}}$_\" + method] = compute_mean_cons_below_threshold(\n",
    "                    allocation=allocation,\n",
    "                    k_rec=k_rec,\n",
    "                )\n",
    "\n",
    "            results.append({\n",
    "                \"$N_{c}$, N_{p}$\": size,\n",
    "                \"k\": k_rec,\n",
    "                \"optimal_time\": optimal_time,\n",
    "                \"relaxed_time\": relaxed_time,\n",
    "                \"grad_time\": grad_time,\n",
    "                **stats,\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c63758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2967afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"experiments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c50cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85b96869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['$N_{c}$, N_{p}$', 'k', 'optimal_time', 'relaxed_time', 'grad_time',\n",
       "       '$\\mathbb{E}[{U_{C}}]$_Baseline',\n",
       "       '$\\sigma(\\mathbb{E}[U_{G}])$_Baseline',\n",
       "       '$\\#(U_{P} < U_{P\\min})/N_{P}$_Baseline',\n",
       "       '$\\sum(V - U_{P})/N_{P^{b}}$_Baseline',\n",
       "       '$\\#(A_{C} > k)/N_{C}$_Baseline',\n",
       "       '$\\sum(A_{C} - k)/N_{A_{c}^{a}}$_Baseline',\n",
       "       '$\\#(A_{C} < k)/N_{C}$_Baseline',\n",
       "       '$\\sum(k - A_{C})/N_{A_{c}^{b}}$_Baseline',\n",
       "       '$\\mathbb{E}[{U_{C}}]$_LP Round',\n",
       "       '$\\sigma(\\mathbb{E}[U_{G}])$_LP Round',\n",
       "       '$\\#(U_{P} < U_{P\\min})/N_{P}$_LP Round',\n",
       "       '$\\sum(V - U_{P})/N_{P^{b}}$_LP Round',\n",
       "       '$\\#(A_{C} > k)/N_{C}$_LP Round',\n",
       "       '$\\sum(A_{C} - k)/N_{A_{c}^{a}}$_LP Round',\n",
       "       '$\\#(A_{C} < k)/N_{C}$_LP Round',\n",
       "       '$\\sum(k - A_{C})/N_{A_{c}^{b}}$_LP Round',\n",
       "       '$\\mathbb{E}[{U_{C}}]$_LP TopK', '$\\sigma(\\mathbb{E}[U_{G}])$_LP TopK',\n",
       "       '$\\#(U_{P} < U_{P\\min})/N_{P}$_LP TopK',\n",
       "       '$\\sum(V - U_{P})/N_{P^{b}}$_LP TopK', '$\\#(A_{C} > k)/N_{C}$_LP TopK',\n",
       "       '$\\sum(A_{C} - k)/N_{A_{c}^{a}}$_LP TopK',\n",
       "       '$\\#(A_{C} < k)/N_{C}$_LP TopK',\n",
       "       '$\\sum(k - A_{C})/N_{A_{c}^{b}}$_LP TopK',\n",
       "       '$\\mathbb{E}[{U_{C}}]$_Grad Round',\n",
       "       '$\\sigma(\\mathbb{E}[U_{G}])$_Grad Round',\n",
       "       '$\\#(U_{P} < U_{P\\min})/N_{P}$_Grad Round',\n",
       "       '$\\sum(V - U_{P})/N_{P^{b}}$_Grad Round',\n",
       "       '$\\#(A_{C} > k)/N_{C}$_Grad Round',\n",
       "       '$\\sum(A_{C} - k)/N_{A_{c}^{a}}$_Grad Round',\n",
       "       '$\\#(A_{C} < k)/N_{C}$_Grad Round',\n",
       "       '$\\sum(k - A_{C})/N_{A_{c}^{b}}$_Grad Round',\n",
       "       '$\\mathbb{E}[{U_{C}}]$_Grad TopK',\n",
       "       '$\\sigma(\\mathbb{E}[U_{G}])$_Grad TopK',\n",
       "       '$\\#(U_{P} < U_{P\\min})/N_{P}$_Grad TopK',\n",
       "       '$\\sum(V - U_{P})/N_{P^{b}}$_Grad TopK',\n",
       "       '$\\#(A_{C} > k)/N_{C}$_Grad TopK',\n",
       "       '$\\sum(A_{C} - k)/N_{A_{c}^{a}}$_Grad TopK',\n",
       "       '$\\#(A_{C} < k)/N_{C}$_Grad TopK',\n",
       "       '$\\sum(k - A_{C})/N_{A_{c}^{b}}$_Grad TopK',\n",
       "       '$\\mathbb{E}[{U_{C}}]$_Lang Round',\n",
       "       '$\\sigma(\\mathbb{E}[U_{G}])$_Lang Round',\n",
       "       '$\\#(U_{P} < U_{P\\min})/N_{P}$_Lang Round',\n",
       "       '$\\sum(V - U_{P})/N_{P^{b}}$_Lang Round',\n",
       "       '$\\#(A_{C} > k)/N_{C}$_Lang Round',\n",
       "       '$\\sum(A_{C} - k)/N_{A_{c}^{a}}$_Lang Round',\n",
       "       '$\\#(A_{C} < k)/N_{C}$_Lang Round',\n",
       "       '$\\sum(k - A_{C})/N_{A_{c}^{b}}$_Lang Round',\n",
       "       '$\\mathbb{E}[{U_{C}}]$_Lang TopK',\n",
       "       '$\\sigma(\\mathbb{E}[U_{G}])$_Lang TopK',\n",
       "       '$\\#(U_{P} < U_{P\\min})/N_{P}$_Lang TopK',\n",
       "       '$\\sum(V - U_{P})/N_{P^{b}}$_Lang TopK',\n",
       "       '$\\#(A_{C} > k)/N_{C}$_Lang TopK',\n",
       "       '$\\sum(A_{C} - k)/N_{A_{c}^{a}}$_Lang TopK',\n",
       "       '$\\#(A_{C} < k)/N_{C}$_Lang TopK',\n",
       "       '$\\sum(k - A_{C})/N_{A_{c}^{b}}$_Lang TopK'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18428faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\#'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\#'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\#'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\#'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\#'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\#'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/317195415.py:4: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  \"$\\mathbb{E}[{U_{C}}]$\",\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/317195415.py:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"$\\sigma(\\mathbb{E}[U_{G}])$\",\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/317195415.py:6: SyntaxWarning: invalid escape sequence '\\#'\n",
      "  \"$\\#(U_{P} < U_{P\\min})/N_{P}$\",\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/317195415.py:7: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"$\\sum(V - U_{P})/N_{P^{b}}$\",\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/317195415.py:8: SyntaxWarning: invalid escape sequence '\\#'\n",
      "  \"$\\#(A_{C} > k)/N_{C}$\",\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/317195415.py:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"$\\sum(A_{C} - k)/N_{A_{c}^{a}}$\",\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/317195415.py:10: SyntaxWarning: invalid escape sequence '\\#'\n",
      "  \"$\\#(A_{C} < k)/N_{C}$\",\n",
      "/var/folders/9l/_y964wyn5fx6bcqmbqjpd9780000gp/T/ipykernel_38848/317195415.py:11: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"$\\sum(k - A_{C})/N_{A_{c}^{b}}$\",\n"
     ]
    }
   ],
   "source": [
    "GROUP_BY_COLS = [\"$N_{c}$, N_{p}$\", \"k\"]\n",
    "METHODS = [\"Baseline\", \"LP Round\", \"LP TopK\", \"Grad Round\", \"Grad TopK\", \"Lang Round\", \"Lang TopK\"]\n",
    "BASE_METRICS = [\n",
    "    \"$\\mathbb{E}[{U_{C}}]$\",\n",
    "    \"$\\sigma(\\mathbb{E}[U_{G}])$\",\n",
    "    \"$\\#(U_{P} < U_{P\\min})/N_{P}$\",\n",
    "    \"$\\sum(V - U_{P})/N_{P^{b}}$\",\n",
    "    \"$\\#(A_{C} > k)/N_{C}$\",\n",
    "    \"$\\sum(A_{C} - k)/N_{A_{c}^{a}}$\",\n",
    "    \"$\\#(A_{C} < k)/N_{C}$\",\n",
    "    \"$\\sum(k - A_{C})/N_{A_{c}^{b}}$\",\n",
    "]\n",
    "\n",
    "def aggregate_wide(df: pd.DataFrame):\n",
    "    # build the dict of aggregations\n",
    "    agg_dict = {\n",
    "        f\"{base}_{m}\": [\"mean\", \"std\"]\n",
    "        for m in METHODS\n",
    "        for base in BASE_METRICS\n",
    "    }\n",
    "    # group and flatten the MultiIndex\n",
    "    grouped = df.groupby(GROUP_BY_COLS).agg(agg_dict)\n",
    "    # flatten columns: e.g. (\"mean_consumer_utility_optimal\",\"mean\") → \"mean_consumer_utility_optimal_mean\"\n",
    "    grouped.columns = [\n",
    "        f\"{col[0]}_{col[1]}\" for col in grouped.columns\n",
    "    ]\n",
    "    return grouped.reset_index()\n",
    "\n",
    "agg_df = aggregate_wide(df)\n",
    "\n",
    "def aggregate_long(df: pd.DataFrame):\n",
    "    # melt into a tall table\n",
    "    value_vars = [\n",
    "        f\"{base}_{m}\"\n",
    "        for m in METHODS\n",
    "        for base in BASE_METRICS\n",
    "    ]\n",
    "    df_long = df.melt(\n",
    "        id_vars=GROUP_BY_COLS,\n",
    "        value_vars=value_vars,\n",
    "        var_name=\"metric_method\",\n",
    "        value_name=\"value\",\n",
    "    )\n",
    "    method_pattern = \"|\".join(re.escape(m) for m in METHODS)\n",
    "    extract_re = rf\"(?P<metric>.*)_(?P<Method>{method_pattern})$\"\n",
    "\n",
    "    # do the extract:\n",
    "    df_long[[\"metric\", \"Method\"]] = df_long[\"metric_method\"].str.extract(extract_re)\n",
    "    # split “mean_consumer_utility_optimal” → (“mean_consumer_utility”, “optimal”)\n",
    "    # now group\n",
    "    return (\n",
    "        df_long\n",
    "        .groupby(GROUP_BY_COLS + [\"Method\", \"metric\"])[\"value\"]\n",
    "        .agg(mean=\"mean\", std=\"std\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "agg_long_df = aggregate_long(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34fd018a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Performance by method and metric}\n",
      "\\label{tab:results}\n",
      "\\resizebox{\\textwidth}{!}{\\begin{tabular}{lllrrrrrrrr}\n",
      "\\toprule\n",
      "$N_{c}$, N_{p}$ & k & Method & $\\#(A_{C} < k)/N_{C}$ & $\\#(A_{C} > k)/N_{C}$ & $\\#(U_{P} < U_{P\\min})/N_{P}$ & $\\mathbb{E}[{U_{C}}]$ & $\\sigma(\\mathbb{E}[U_{G}])$ & $\\sum(A_{C} - k)/N_{A_{c}^{a}}$ & $\\sum(V - U_{P})/N_{P^{b}}$ & $\\sum(k - A_{C})/N_{A_{c}^{b}}$ \\\\\n",
      "\\midrule\n",
      "100 & 5 & Baseline & 0.00 (0.00) & 0.00 (0.00) & 0.00 (0.00) & 0.94 (0.00) & 1.19 (0.00) &  &  &  \\\\\n",
      "100 & 5 & Grad Round & 0.00 (0.00) & 0.03 (0.01) & 0.02 (0.01) & 0.92 (0.00) & 1.19 (0.00) & -1.00 (0.00) & 1.00 (0.00) &  \\\\\n",
      "100 & 5 & Grad TopK & 0.00 (0.00) & 0.00 (0.00) & 0.03 (0.01) & 0.92 (0.00) & 1.19 (0.00) &  & 1.00 (0.00) &  \\\\\n",
      "100 & 5 & LP Round & 0.01 (0.01) & 0.00 (0.00) & 0.00 (0.00) & 0.94 (0.00) & 1.19 (0.00) &  &  & 1.00 (0.00) \\\\\n",
      "100 & 5 & LP TopK & 0.00 (0.00) & 0.00 (0.00) & 0.00 (0.00) & 0.94 (0.00) & 1.19 (0.00) &  &  &  \\\\\n",
      "100 & 5 & Lang Round & 0.00 (0.00) & 0.00 (0.00) & 0.00 (0.00) & 0.94 (0.00) & 1.19 (0.00) &  &  &  \\\\\n",
      "100 & 5 & Lang TopK & 0.00 (0.00) & 0.00 (0.00) & 0.00 (0.00) & 0.94 (0.00) & 1.19 (0.00) &  &  &  \\\\\n",
      "100 & 10 & Baseline & 0.00 (0.00) & 0.00 (0.00) & 0.00 (0.00) & 0.94 (0.00) & 2.38 (0.00) &  &  &  \\\\\n",
      "100 & 10 & Grad Round & 0.00 (0.00) & 0.01 (0.00) & 0.00 (0.00) & 0.92 (0.00) & 2.37 (0.00) & -1.00 (0.00) &  &  \\\\\n",
      "100 & 10 & Grad TopK & 0.00 (0.00) & 0.00 (0.00) & 0.00 (0.00) & 0.92 (0.00) & 2.38 (0.00) &  &  &  \\\\\n",
      "100 & 10 & LP Round & 0.00 (0.01) & 0.00 (0.01) & 0.00 (0.00) & 0.94 (0.00) & 2.37 (0.00) & -1.00 (nan) &  & 1.00 (nan) \\\\\n",
      "100 & 10 & LP TopK & 0.00 (0.00) & 0.00 (0.00) & 0.00 (0.01) & 0.94 (0.00) & 2.38 (0.00) &  & 1.00 (nan) &  \\\\\n",
      "100 & 10 & Lang Round & 0.00 (0.00) & 0.00 (0.00) & 0.00 (0.00) & 0.94 (0.00) & 2.38 (0.00) &  &  &  \\\\\n",
      "100 & 10 & Lang TopK & 0.00 (0.00) & 0.00 (0.00) & 0.00 (0.00) & 0.94 (0.00) & 2.38 (0.00) &  &  &  \\\\\n",
      "100 & 25 & Baseline & 0.00 (0.00) & 0.00 (0.00) & 0.00 (0.00) & 0.92 (0.00) & 5.94 (0.00) &  &  &  \\\\\n",
      "100 & 25 & Grad Round & 0.00 (0.00) & 0.01 (0.01) & 0.00 (0.01) & 0.91 (0.00) & 5.94 (0.00) & -1.00 (0.00) & 1.00 (nan) &  \\\\\n",
      "100 & 25 & Grad TopK & 0.00 (0.00) & 0.00 (0.00) & 0.00 (0.01) & 0.91 (0.00) & 5.94 (0.00) &  & 1.00 (nan) &  \\\\\n",
      "100 & 25 & LP Round & 0.00 (0.00) & 0.00 (0.00) & 0.00 (0.00) & 0.92 (0.00) & 5.94 (0.00) &  &  &  \\\\\n",
      "100 & 25 & LP TopK & 0.00 (0.00) & 0.00 (0.00) & 0.00 (0.00) & 0.92 (0.00) & 5.94 (0.00) &  &  &  \\\\\n",
      "100 & 25 & Lang Round & 0.04 (0.02) & 0.02 (0.02) & 0.02 (0.01) & 0.92 (0.00) & 5.94 (0.01) & -1.00 (0.00) & 1.00 (0.00) & 1.00 (0.00) \\\\\n",
      "100 & 25 & Lang TopK & 0.00 (0.00) & 0.00 (0.00) & 0.02 (0.02) & 0.92 (0.00) & 5.94 (0.00) &  & 1.00 (0.00) &  \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) combine mean+std into one column\n",
    "def fmt(x, y):\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return f\"{x:.2f} ({y:.2f})\"\n",
    "\n",
    "agg_long_df[\"mean_std\"] = agg_long_df.apply(\n",
    "    lambda row: fmt(row[\"mean\"], row[\"std\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 2) pivot so metrics become columns\n",
    "pivot = (\n",
    "    agg_long_df\n",
    "    .pivot_table(\n",
    "        index=[\"$N_{c}$, N_{p}$\", \"k\", \"Method\"],\n",
    "        columns=\"metric\",\n",
    "        values=\"mean_std\",\n",
    "        aggfunc=\"first\"\n",
    "    )\n",
    "    # flatten the column Index\n",
    "    .rename_axis(None, axis=1)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 3) export to LaTeX\n",
    "latex = pivot.to_latex(\n",
    "    index=False,\n",
    "    na_rep=\"\",\n",
    "    column_format=\"lll\" + \"r\" * (pivot.shape[1] - 3),\n",
    "    longtable=False,\n",
    "    caption=\"Performance by method and metric\",\n",
    "    label=\"tab:results\",\n",
    "    escape=False,\n",
    "    bold_rows=False,\n",
    "    multicolumn=True,\n",
    ")\n",
    "\n",
    "# add \\resizebox{\\textwidth}{!}{\\begin{tabular}\n",
    "latex = latex.replace(\n",
    "    \"\\\\begin{tabular}\",\n",
    "    \"\\\\resizebox{\\\\textwidth}{!}{\\\\begin{tabular}\"\n",
    ").replace(\n",
    "    \"\\\\end{tabular}\",\n",
    "    \"\\\\end{tabular}}\"\n",
    ")\n",
    "\n",
    "print(latex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-thesis",
   "language": "python",
   "name": "msc-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

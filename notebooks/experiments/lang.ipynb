{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc2ef9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json\n",
    "import cvxpy as cp\n",
    "\n",
    "import torch\n",
    "import torch\n",
    "from src.problems.utils import sample_data_for_group\n",
    "from src.problems.problems import compute_producer_optimal_solution, _compute_consumer_optimal_solution_cvar\n",
    "from src.problems.gradient_problem import compute_consumer_optimal_solution_cvar_grad\n",
    "from src.problems.problems import (\n",
    "    _compute_consumer_optimal_solution_cvar,\n",
    "    _compute_consumer_optimal_solution_mean,\n",
    "    _compute_consumer_optimal_solution_min\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7570999",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_ROOT = Path(\"../../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "883b9046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(DATA_PATH_ROOT / \"amazon_predictions.npy\", \"rb\") as f:\n",
    "    REL_MATRIX = np.load(f)\n",
    "\n",
    "with open(DATA_PATH_ROOT / \"amazon_user_groups.json\", \"r\") as f:\n",
    "    GROUPS_MAP = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "bf192b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CONSUMERS = 500\n",
    "N_PRODUCERS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b6b6c61",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampled_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msampled_matrix\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sampled_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "sampled_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a035f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_matrix, consumer_ids, group_assignments = sample_data_for_group(\n",
    "    n_consumers=N_CONSUMERS,\n",
    "    n_producers=N_PRODUCERS,\n",
    "    groups_map=GROUPS_MAP,\n",
    "    group_key=\"top_category\",\n",
    "    data=REL_MATRIX,\n",
    "    seed=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ddcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_allocations = _compute_consumer_optimal_solution_mean(\n",
    "    rel_matrix=sampled_matrix,\n",
    "    k_rec=10,\n",
    "    producer_max_min_utility=10,\n",
    "    gamma=0.5,\n",
    "    solver=cp.GUROBI\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7a4fedba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def async_augmented_lagrangian(\n",
    "    r: np.ndarray,\n",
    "    k: int,\n",
    "    U: float,\n",
    "    gamma: float,\n",
    "    rho0: float = 1.0,\n",
    "    rho_mult: float = 1.05,\n",
    "    max_epochs: int = 200,\n",
    "    tol: float = 1e-3,\n",
    "    jitter: float = 1e-3\n",
    "):\n",
    "    \"\"\"\n",
    "    Asynchronous row-by-row Augmented Lagrangian for the\n",
    "    max-mean utility problem with (i) exactly k picks per\n",
    "    consumer and (ii) >= h picks per producer.\n",
    "\n",
    "    Returns final A, mean utility, and final beta.\n",
    "    \"\"\"\n",
    "    n, m = r.shape\n",
    "    h = math.ceil(gamma * U)\n",
    "\n",
    "    # initialize\n",
    "    A    = np.zeros((n, m), dtype=float)\n",
    "    beta = np.zeros(m)\n",
    "    rho  = rho0\n",
    "    cov  = A.sum(axis=0)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        any_change = False\n",
    "\n",
    "        for i in range(n):\n",
    "            # build this consumer's score\n",
    "            # note: cov and beta include all previous updates\n",
    "            score = (r[i]/n) + beta + rho * np.maximum(0, h - cov)\n",
    "            score += np.random.uniform(0, jitter, size=m)\n",
    "\n",
    "            # pick top-k for row i\n",
    "            new_row = np.zeros(m, dtype=float)\n",
    "            topk_idxs = np.argpartition(-score, k-1)[:k]\n",
    "            new_row[topk_idxs] = 1.0\n",
    "\n",
    "            # if this row really changed, commit it\n",
    "            if not np.array_equal(new_row, A[i]):\n",
    "                # remove old coverage, add new\n",
    "                cov -= A[i]\n",
    "                cov += new_row\n",
    "                A[i] = new_row\n",
    "                any_change = True\n",
    "\n",
    "                # immediate dual update on all producers\n",
    "                # g_j = h - cov_j  (positive if still under-covered)\n",
    "                g = h - cov\n",
    "                beta = np.maximum(0.0, beta + rho * g)\n",
    "\n",
    "                # ramp penalty a bit every row\n",
    "                rho *= rho_mult ** (1.0/n)\n",
    "\n",
    "        # check stopping: are all cov >= h?\n",
    "        min_cov = cov.min()\n",
    "        if min_cov >= h - tol:\n",
    "            break\n",
    "        # if completely no row changed, bump rho heavier to force movement\n",
    "        if not any_change:\n",
    "            rho *= 2\n",
    "\n",
    "    mean_util = (A * r).sum(axis=1).mean()\n",
    "    return A, mean_util, beta\n",
    "\n",
    "r = async_augmented_lagrangian(\n",
    "    r=sampled_matrix,\n",
    "    k=10,\n",
    "    U=3,\n",
    "    gamma=1,\n",
    "    rho0=1.0,\n",
    "    rho_mult=2.0,\n",
    "    max_epochs=200,\n",
    "    tol=1e-3,\n",
    "    jitter=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c5f7f5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(9.528643500775212)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_allocations[1] * sampled_matrix).sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b717c1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.,  13.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,  14.,   3.,   3.,   3.,   3.,\n",
       "         8.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,  23.,   3.,\n",
       "         3.,  93.,   3.,   3.,  16.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3., 345.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,  46., 255.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "       231.,   3.,   3.,   3.,  23.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "       187.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "        11.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,  31.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3., 423.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,  68.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,  18.,\n",
       "         3.,   3.,   3.,   3.,  17.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3., 237.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   4.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   8.,\n",
       "         3.,   3.,   8.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,  59.,   3.,   3.,  11.,   3.,   3.,   3., 267.,\n",
       "         3.,   3.,   3.,   3.,   3.,   5.,   3.,   3.,   3.,  90.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3., 407.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3., 208.,   3.,\n",
       "         3.,   3.,   3.,   6.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   8.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,  13.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,  57.,  18.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         4.,   3.,   3., 366.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,\n",
       "         3.,   3.,   3.,   3.,   3.,   3.,   3.,   3.,   5.,   3.,   3.,\n",
       "        11.,   3.,   3.,   3.,   3.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_allocations[1].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d34f2457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.,  11.,   6.,   6.,   6.,   5.,   6.,   6.,   5.,   6.,   5.,\n",
       "         6.,   5.,   6.,   6.,   6.,   6.,  18.,   6.,   6.,   5.,   6.,\n",
       "         7.,   6.,   5.,   6.,   6.,   6.,   6.,   6.,   5.,  18.,   6.,\n",
       "         5.,  50.,   5.,   6.,  19.,   6.,   6.,   6.,   6.,   6.,   5.,\n",
       "         6., 194.,   5.,   6.,   5.,   5.,   5.,   6.,   6.,   5.,   5.,\n",
       "         6.,   5.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,\n",
       "         6.,   6.,   5.,   6.,   5.,   6.,   6.,   6.,   6.,   6.,   6.,\n",
       "         6.,   6.,  39., 169.,   5.,   6.,   6.,   6.,   5.,   6.,   6.,\n",
       "       150.,   6.,   6.,   6.,  21.,   5.,   6.,   5.,   6.,   6.,   6.,\n",
       "       130.,   6.,   5.,   6.,   5.,   6.,   6.,   6.,   5.,   6.,   6.,\n",
       "        12.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,   5.,   6.,   6.,\n",
       "         6.,  24.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,\n",
       "         6.,   6.,   6.,   6.,   6.,   6.,   6.,   6., 222.,   6.,   6.,\n",
       "         6.,   6.,   6.,   5.,   6.,   6.,  54.,   6.,   5.,   6.,   6.,\n",
       "         6.,   5.,   5.,   6.,   5.,   6.,   6.,   6.,   6.,   5.,   5.,\n",
       "         6.,   6.,   6.,   5.,   6.,   6.,   6.,   5.,   6.,   6.,  18.,\n",
       "         6.,   5.,   5.,   6.,  13.,   6.,   6.,   6.,   6.,   6.,   5.,\n",
       "         6.,   5.,   6.,   5.,   6.,   5.,   5.,   5.,   5.,   6.,   6.,\n",
       "         6.,   6.,   5.,   5.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,\n",
       "         5.,   5.,   6.,   5.,   6.,   6.,   6.,   6.,   5.,   6.,   5.,\n",
       "         5.,   5.,   6.,   6.,   9.,   6.,   5.,   5.,   6., 141.,   6.,\n",
       "         6.,   6.,   6.,   5.,   6.,   6.,   6.,   5.,   6.,   5.,   6.,\n",
       "         6.,   6.,   6.,   5.,   6.,   6.,   6.,   6.,   6.,   7.,   6.,\n",
       "         6.,   5.,   6.,   6.,   6.,   5.,   6.,   5.,   6.,   6.,  14.,\n",
       "         5.,   6.,   8.,   6.,   6.,   6.,   5.,   6.,   6.,   6.,   6.,\n",
       "         6.,   5.,   5.,  52.,   6.,   5.,  15.,   5.,   6.,   6., 164.,\n",
       "         6.,   5.,   6.,   6.,   6.,   9.,   6.,   6.,   5.,  47.,   6.,\n",
       "         6.,   5.,   5.,   6.,   6.,   6.,   6.,   6.,   6., 220.,   6.,\n",
       "         6.,   6.,   6.,   5.,   6.,   6.,   6.,   6.,   6.,   6.,   5.,\n",
       "         5.,   6.,   6.,   5.,   6.,   6.,   6.,   5.,   6.,   5.,   6.,\n",
       "         6.,   6.,   6.,   6.,   6.,   5.,   6.,   6.,   5., 143.,   6.,\n",
       "         6.,   6.,   6.,  10.,   6.,   5.,   6.,   6.,   6.,   6.,   6.,\n",
       "         5.,   5.,   6.,  12.,   6.,   6.,   6.,   6.,   6.,   6.,   5.,\n",
       "         6.,   5.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,\n",
       "         8.,   6.,   5.,   6.,   6.,   6.,   5.,   6.,   6.,   6.,   6.,\n",
       "         6.,   6.,   6.,   5.,   6.,   5.,   6.,   6.,   6.,   6.,   6.,\n",
       "         5.,   5.,   6.,   6.,   6.,   6.,   6.,   5.,   6.,   6.,   6.,\n",
       "         5.,   6.,   6.,   6.,   6.,   6.,   5.,   6.,   5.,  21.,   5.,\n",
       "         6.,   6.,   6.,   6.,   6.,   6.,   5.,   6.,   5.,   5.,   6.,\n",
       "         6.,   6.,   6.,   5.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,\n",
       "         6.,   6.,   5.,   6.,   6.,   5.,   9.,   6.,   6.,  46.,  17.,\n",
       "         5.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,   5.,   6.,   6.,\n",
       "         6.,   6.,   6.,   9.,   6.,   5.,   6.,   6.,   5.,   5.,   6.,\n",
       "         7.,   6.,   6., 211.,   6.,   5.,   6.,   5.,   6.,   6.,   6.,\n",
       "         6.,   6.,   6.,   6.,   6.,   6.,   5.,   5.,   9.,   5.,   6.,\n",
       "         9.,   5.,   6.,   6.,   6.])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0].sum(axis=0)  # sum of all producers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "83b1056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def async_aug_lagrange_tame(\n",
    "    r: np.ndarray,\n",
    "    k: int,\n",
    "    U: float,\n",
    "    gamma: float,\n",
    "    rho: float = 0.5,       # small, fixed penalty\n",
    "    alpha: float = 0.75,    # exponent for diminishing step size\n",
    "    max_epochs: int = 200,\n",
    "    tol: float = 1e-3,\n",
    "    jitter: float = 1e-4\n",
    "):\n",
    "    \"\"\"\n",
    "    Asynchronous AL with small, fixed rho and diminishing dual steps.\n",
    "    \"\"\"\n",
    "    n, m = r.shape\n",
    "    h      = math.ceil(gamma * U)\n",
    "    A      = np.zeros((n, m), dtype=float)\n",
    "    beta   = np.zeros(m)\n",
    "    coverage = A.sum(axis=0)\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        any_change = False\n",
    "\n",
    "        # dual step size\n",
    "        eta = rho / (epoch ** alpha)\n",
    "\n",
    "        for i in range(n):\n",
    "            # violation vector (positive if under)\n",
    "            viol = np.maximum(0, h - coverage)\n",
    "\n",
    "            # per-entry score\n",
    "            score = (r[i] / n) + beta + rho * viol\n",
    "            score += np.random.rand(m) * jitter\n",
    "\n",
    "            # pick top-k\n",
    "            new_row = np.zeros(m)\n",
    "            topk   = np.argpartition(-score, k-1)[:k]\n",
    "            new_row[topk] = 1.0\n",
    "\n",
    "            if not np.array_equal(new_row, A[i]):\n",
    "                # commit change\n",
    "                coverage -= A[i]\n",
    "                coverage += new_row\n",
    "                A[i] = new_row\n",
    "                any_change = True\n",
    "\n",
    "                # dual update (projected subgradient ascent)\n",
    "                # g_j = h - coverage_j\n",
    "                g = h - coverage\n",
    "                beta = np.maximum(0.0, beta + eta * g)\n",
    "\n",
    "        # stop if all columns â‰¥ h\n",
    "        if coverage.min() >= h - tol:\n",
    "            break\n",
    "\n",
    "        # if nothing moved, you might bump rho slightly or just continue\n",
    "\n",
    "    mean_util = (A * r).sum(axis=1).mean()\n",
    "    return A, mean_util, beta, coverage\n",
    "\n",
    "r = async_aug_lagrange_tame(\n",
    "    r=sampled_matrix,\n",
    "    k=10,\n",
    "    U=5,\n",
    "    gamma=0.5,\n",
    "    rho=0.5,\n",
    "    alpha=0.75,\n",
    "    max_epochs=200,\n",
    "    tol=1e-3,\n",
    "    jitter=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "79d0d096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0].sum(axis=0).min()  # sum of all producers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262d4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def optimize_allocations_with_grad(rel_matrix, k_rec, producer_max_min_utility, gamma):\n",
    "    N, M = rel_matrix.shape\n",
    "    x0 = np.full(N * M, 1 / M)\n",
    "\n",
    "    # Objective (negative utility since we minimize)\n",
    "    def objective(x):\n",
    "        x_mat = x.reshape(N, M)\n",
    "        return -np.mean(np.sum(x_mat * rel_matrix, axis=1))\n",
    "\n",
    "    # Gradient of objective\n",
    "    def grad_objective(x):\n",
    "        grad = - (rel_matrix / N).flatten()\n",
    "        return grad\n",
    "\n",
    "    # Equality constraints (consumer-level)\n",
    "    cons_eq = [{\n",
    "        'type': 'eq',\n",
    "        'fun': lambda x, i=i: np.sum(x.reshape(N, M)[i]) - k_rec,\n",
    "        'jac': lambda x, i=i: np.array(\n",
    "            [(1 if (idx // M) == i else 0) for idx in range(N*M)]\n",
    "        )\n",
    "    } for i in range(N)]\n",
    "\n",
    "    # Inequality constraints (producer-level)\n",
    "    cons_ineq = [{\n",
    "        'type': 'ineq',\n",
    "        'fun': lambda x, j=j: np.sum(x.reshape(N, M)[:, j]) - gamma * producer_max_min_utility,\n",
    "        'jac': lambda x, j=j: np.array(\n",
    "            [(1 if (idx % M) == j else 0) for idx in range(N*M)]\n",
    "        )\n",
    "    } for j in range(M)]\n",
    "\n",
    "    constraints = cons_eq + cons_ineq\n",
    "\n",
    "    # Bounds\n",
    "    bounds = [(0, 1) for _ in range(N*M)]\n",
    "\n",
    "    # Solve with SLSQP\n",
    "    result = minimize(\n",
    "        objective, x0, method='SLSQP', jac=grad_objective,\n",
    "        constraints=constraints, bounds=bounds,\n",
    "        options={'ftol': 1e-9, 'disp': True, 'maxiter': 500}\n",
    "    )\n",
    "\n",
    "    if not result.success:\n",
    "        raise ValueError(\"Optimization failed:\", result.message)\n",
    "\n",
    "    optimal_allocations = result.x.reshape(N, M)\n",
    "    optimal_value = -result.fun  # revert sign back\n",
    "\n",
    "    return optimal_value, optimal_allocations\n",
    "\n",
    "# Example usage:\n",
    "rel_matrix = sampled_matrix[:100, :100]  # Use a smaller matrix for testing\n",
    "k_rec = 2\n",
    "producer_max_min_utility = 1.0\n",
    "gamma = 0.5\n",
    "\n",
    "optimal_value, allocations = optimize_allocations_with_grad(\n",
    "    rel_matrix, k_rec, producer_max_min_utility, gamma\n",
    ")\n",
    "\n",
    "print(\"Optimal Mean Utility:\", optimal_value)\n",
    "print(\"Optimal Allocations:\\n\", allocations.round())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "482c9419",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 85\u001b[0m\n\u001b[1;32m     79\u001b[0m     mean_utility \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((allocations \u001b[38;5;241m*\u001b[39m rel_matrix)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mean_utility, allocations\n\u001b[0;32m---> 85\u001b[0m mean_utility, optimal_allocations \u001b[38;5;241m=\u001b[39m \u001b[43msolve_with_dual_ascent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampled_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-20\u001b[39;49m\n\u001b[1;32m     87\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 58\u001b[0m, in \u001b[0;36msolve_with_dual_ascent\u001b[0;34m(rel_matrix, k_rec, producer_max_min_utility, gamma, max_iters, step_size, tolerance)\u001b[0m\n\u001b[1;32m     56\u001b[0m allocated \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m consumer \u001b[38;5;129;01min\u001b[39;00m potential_consumers:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mallocations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconsumer\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m k_rec \u001b[38;5;129;01mand\u001b[39;00m allocations[consumer, producer] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     59\u001b[0m         allocations[consumer, producer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     60\u001b[0m         allocated \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/github/msc-thesis/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:52\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def solve_with_dual_ascent(\n",
    "    rel_matrix: np.ndarray,\n",
    "    k_rec: int,\n",
    "    producer_max_min_utility: float,\n",
    "    gamma: float,\n",
    "    max_iters: int = 1000,\n",
    "    step_size: float = 0.1,\n",
    "    tolerance: float = 1e-4,\n",
    "):\n",
    "    n_consumers, n_producers = rel_matrix.shape\n",
    "\n",
    "    lambda_consumer = np.zeros(n_consumers)\n",
    "    mu_producer = np.zeros(n_producers)\n",
    "\n",
    "    for iteration in range(max_iters):\n",
    "        prev_lambda = lambda_consumer.copy()\n",
    "        prev_mu = mu_producer.copy()\n",
    "\n",
    "        allocations = (rel_matrix / n_consumers) + mu_producer - lambda_consumer[:, None]\n",
    "        allocations = np.clip(allocations, 0, 1)\n",
    "\n",
    "        lambda_gradient = allocations.sum(axis=1) - k_rec\n",
    "        mu_gradient = gamma * producer_max_min_utility - allocations.sum(axis=0)\n",
    "\n",
    "        lambda_consumer += step_size * lambda_gradient\n",
    "        mu_producer += step_size * mu_gradient\n",
    "        mu_producer = np.maximum(0, mu_producer)\n",
    "\n",
    "        dual_change = np.linalg.norm(lambda_consumer - prev_lambda) + np.linalg.norm(mu_producer - prev_mu)\n",
    "        if dual_change < tolerance:\n",
    "            break\n",
    "\n",
    "    allocations = (rel_matrix / n_consumers) + mu_producer - lambda_consumer[:, None]\n",
    "    allocations = np.clip(allocations, 0, 1)\n",
    "\n",
    "    for i in range(n_consumers):\n",
    "        top_indices = np.argsort(allocations[i])[::-1][:k_rec]\n",
    "        allocations[i, :] = 0\n",
    "        allocations[i, top_indices] = 1\n",
    "\n",
    "    col_sums = allocations.sum(axis=0)\n",
    "    required_allocations = gamma * producer_max_min_utility\n",
    "\n",
    "    # Robust producer constraint enforcement\n",
    "    while np.any(col_sums < required_allocations):\n",
    "        deficit_producers = np.where(col_sums < required_allocations)[0]\n",
    "        for producer in deficit_producers:\n",
    "            deficit = int(required_allocations - col_sums[producer])\n",
    "            potential_consumers = np.argsort(-rel_matrix[:, producer])\n",
    "            allocated = 0\n",
    "            for consumer in potential_consumers:\n",
    "                if allocations[consumer].sum() < k_rec and allocations[consumer, producer] == 0:\n",
    "                    allocations[consumer, producer] = 1\n",
    "                    allocated += 1\n",
    "                    if allocated >= deficit:\n",
    "                        break\n",
    "            col_sums = allocations.sum(axis=0)\n",
    "\n",
    "        # If stuck, free allocations from overloaded producers\n",
    "        if np.any(col_sums > required_allocations):\n",
    "            overloaded_producers = np.where(col_sums > required_allocations)[0]\n",
    "            for producer in overloaded_producers:\n",
    "                excess = int(col_sums[producer] - required_allocations)\n",
    "                consumers_assigned = np.where(allocations[:, producer] == 1)[0]\n",
    "                for consumer in consumers_assigned:\n",
    "                    if allocations[consumer].sum() > k_rec:\n",
    "                        allocations[consumer, producer] = 0\n",
    "                        excess -= 1\n",
    "                        if excess <= 0:\n",
    "                            break\n",
    "            col_sums = allocations.sum(axis=0)\n",
    "\n",
    "    mean_utility = np.mean((allocations * rel_matrix).sum(axis=1))\n",
    "\n",
    "    return mean_utility, allocations\n",
    "\n",
    "\n",
    "\n",
    "mean_utility, optimal_allocations = solve_with_dual_ascent(\n",
    "    sampled_matrix, 10, 10, 0.5, tolerance=1e-20\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ca53c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_allocations = _compute_consumer_optimal_solution_mean(\n",
    "    rel_matrix=sampled_matrix,\n",
    "    k_rec=10,\n",
    "    producer_max_min_utility=10,\n",
    "    gamma=0.5,\n",
    "    solver=cp.GUROBI\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99073c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5., 21., 51., 22.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5., 76.,\n",
       "        5., 85.,  5.,  5.,  5.,  5.,  5.,  5., 76.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5., 12.,  5.,  5., 23.,\n",
       "       40., 26.,  5.,  5.,  5., 82.,  5.,  5.,  5.,  5.,  7.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5., 24.,  5.,  5.,  6.,\n",
       "        5.,  5., 11.,  5.,  5.,  6.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5., 13.,  9.,  5.,  5.,  5.,  5.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_allocations[1].sum(axis=0)  # sum of all producers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b43d3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   9.,  19.,\n",
       "         6.,   0.,   1.,   0.,   0.,   0.,   0.,   2.,   0.,   0.,   0.,\n",
       "         0.,   4.,   0.,  22.,  78., 100.,  78.,  78.,  78.,  78.,  78.,\n",
       "        78.,  22.,   0.,  79.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   1.,   0.,   6.,   0.,   0.,  11.,  16.,  10.,   0.,\n",
       "         0.,   0.,  22.,   0.,   0.,   0.,   0.,   6.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   9.,   0.,   0.,\n",
       "         7.,   0.,   0.,   2.,   0.,   0.,   6.,   0.,   0.,   0.,   0.,\n",
       "         1.,   0.,   0.,   0.,   1.,   0.,   4.,   9.,   0.,   0.,   0.,\n",
       "        78.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_allocations.sum(axis=0)  # sum of all producers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b02359dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500: util=3.9690, max|ci|=6.3529, min_prod=3.9996\n",
      "Epoch 1000: util=2.3538, max|ci|=7.5739, min_prod=2.3680\n",
      "Epoch 1500: util=12.6000, max|ci|=19.3618, min_prod=11.5018\n",
      "Epoch 2000: util=2.5822, max|ci|=8.4394, min_prod=2.5751\n",
      "Epoch 2500: util=6.1808, max|ci|=39.9784, min_prod=4.0663\n",
      "Epoch 3000: util=4.2114, max|ci|=7.8515, min_prod=3.7652\n",
      "Epoch 3500: util=4.5326, max|ci|=35.7553, min_prod=3.0172\n",
      "Epoch 4000: util=4.0862, max|ci|=53.5875, min_prod=3.9011\n",
      "Epoch 4500: util=5.0665, max|ci|=38.4551, min_prod=4.2985\n",
      "Epoch 5000: util=2.6227, max|ci|=48.8652, min_prod=2.5539\n",
      "Epoch 5500: util=11.5624, max|ci|=40.4783, min_prod=6.0378\n",
      "Epoch 6000: util=2.3059, max|ci|=26.7210, min_prod=1.7196\n",
      "Epoch 6500: util=17.2119, max|ci|=50.6612, min_prod=6.9722\n",
      "Epoch 7000: util=2.5568, max|ci|=44.8316, min_prod=1.9707\n",
      "Epoch 7500: util=7.5786, max|ci|=44.9026, min_prod=4.7659\n",
      "Epoch 8000: util=5.4476, max|ci|=38.7051, min_prod=2.8088\n",
      "Epoch 8500: util=5.6993, max|ci|=73.5864, min_prod=4.1271\n",
      "Epoch 9000: util=9.2077, max|ci|=49.0608, min_prod=5.8466\n",
      "Epoch 9500: util=5.3016, max|ci|=55.5535, min_prod=2.8781\n",
      "Epoch 10000: util=22.3458, max|ci|=63.6833, min_prod=15.6877\n",
      "Epoch 10500: util=7.0143, max|ci|=60.3134, min_prod=4.0954\n",
      "Epoch 11000: util=5.6791, max|ci|=65.9230, min_prod=4.0144\n",
      "Epoch 11500: util=17.0172, max|ci|=69.3219, min_prod=12.3736\n",
      "Epoch 12000: util=12.4248, max|ci|=71.8849, min_prod=11.0212\n",
      "Epoch 12500: util=5.6433, max|ci|=66.4597, min_prod=3.8672\n",
      "Epoch 13000: util=8.2049, max|ci|=68.4343, min_prod=6.8224\n",
      "Epoch 13500: util=15.8904, max|ci|=71.5031, min_prod=12.3298\n",
      "Epoch 14000: util=9.4539, max|ci|=73.0870, min_prod=7.6305\n",
      "Epoch 14500: util=6.3809, max|ci|=67.3470, min_prod=4.6388\n",
      "Epoch 15000: util=4.0572, max|ci|=63.4043, min_prod=2.4426\n",
      "Epoch 15500: util=11.8514, max|ci|=72.5511, min_prod=10.7547\n",
      "Epoch 16000: util=14.1023, max|ci|=73.6907, min_prod=11.8540\n",
      "Epoch 16500: util=10.2292, max|ci|=72.6292, min_prod=9.1490\n",
      "Epoch 17000: util=5.8212, max|ci|=68.3387, min_prod=3.3714\n",
      "Epoch 17500: util=13.9068, max|ci|=76.3954, min_prod=14.6187\n",
      "Epoch 18000: util=13.6081, max|ci|=72.7262, min_prod=12.3230\n",
      "Epoch 18500: util=10.2565, max|ci|=73.8835, min_prod=9.3506\n",
      "Epoch 19000: util=8.9014, max|ci|=74.8949, min_prod=8.0953\n",
      "Epoch 19500: util=3.5397, max|ci|=71.6735, min_prod=2.8900\n",
      "Epoch 20000: util=23.0812, max|ci|=76.7267, min_prod=23.6566\n",
      "Epoch 20500: util=13.9974, max|ci|=71.3384, min_prod=13.1426\n",
      "Epoch 21000: util=9.6504, max|ci|=73.3282, min_prod=8.7610\n",
      "Epoch 21500: util=8.2822, max|ci|=68.6449, min_prod=6.4904\n",
      "Epoch 22000: util=2.3531, max|ci|=44.5190, min_prod=1.8739\n",
      "Epoch 22500: util=26.1898, max|ci|=71.9215, min_prod=24.3355\n",
      "Epoch 23000: util=7.5063, max|ci|=70.3191, min_prod=6.7613\n",
      "Epoch 23500: util=5.9840, max|ci|=70.0125, min_prod=3.7905\n",
      "Epoch 24000: util=6.2242, max|ci|=74.3739, min_prod=4.4042\n",
      "Epoch 24500: util=9.1047, max|ci|=81.5259, min_prod=9.0618\n",
      "Epoch 25000: util=12.2884, max|ci|=71.4897, min_prod=11.6134\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 89\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# Final allocations\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msigmoid(logits)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m---> 89\u001b[0m allocations \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_consumer_optimal_with_lagrangian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrel_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_matrix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_rec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproducer_max_min_utility\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_primal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_dual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     98\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[167], line 67\u001b[0m, in \u001b[0;36mcompute_consumer_optimal_with_lagrangian\u001b[0;34m(rel_matrix, k_rec, producer_max_min_utility, gamma, lr_primal, lr_dual, max_epochs, verbose)\u001b[0m\n\u001b[1;32m     65\u001b[0m opt_primal\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     66\u001b[0m L\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 67\u001b[0m \u001b[43mopt_primal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# ---- Dual update (maximize L wrt alpha,beta) ----\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# we perform gradient ascent by minimizing -L\u001b[39;00m\n\u001b[1;32m     71\u001b[0m opt_dual\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/github/msc-thesis/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:478\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m cast(Optimizer, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    477\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 478\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# call optimizer step pre hooks\u001b[39;49;00m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_global_optimizer_pre_hooks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step_pre_hooks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/msc-thesis/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:769\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m--> 769\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_exit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RecordFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    771\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39m_record_function_exit(record)\n",
      "File \u001b[0;32m~/github/msc-thesis/.venv/lib/python3.12/site-packages/torch/_ops.py:947\u001b[0m, in \u001b[0;36mTorchBindOpOverload.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 947\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_must_dispatch_in_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;66;03m# When any inputs are FakeScriptObject, we need to\u001b[39;00m\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;66;03m# skip c++ dispatcher and dispatch in python through _get_dispatch of python_dispatcher\u001b[39;00m\n\u001b[1;32m    950\u001b[0m         \u001b[38;5;66;03m# because C++ dispatcher will check the schema and cannot recognize FakeScriptObject.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m         \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    952\u001b[0m         \u001b[38;5;66;03m# Note:\u001b[39;00m\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;66;03m# 1. We only register the torchbind op temporarily as effectful op because we only want\u001b[39;00m\n\u001b[1;32m    954\u001b[0m         \u001b[38;5;66;03m#    the effect token functionalization logic to be applied during tracing. Otherwise, the behavior\u001b[39;00m\n\u001b[1;32m    955\u001b[0m         \u001b[38;5;66;03m#    of the eagerly executing the op might change after tracing.\u001b[39;00m\n\u001b[1;32m    956\u001b[0m         \u001b[38;5;66;03m# 2. We don't want to register the op as effectful for all torchbind ops in ctor because this might\u001b[39;00m\n\u001b[1;32m    957\u001b[0m         \u001b[38;5;66;03m#    cause unexpected behavior for some autograd.profiler ops e.g. profiler._record_function_exit._RecordFunction.\u001b[39;00m\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_as_effectful_op_temporarily():\n\u001b[1;32m    959\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_in_python(args, kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fallthrough_keys())\n",
      "File \u001b[0;32m~/github/msc-thesis/.venv/lib/python3.12/site-packages/torch/_ops.py:1001\u001b[0m, in \u001b[0;36m_must_dispatch_in_python\u001b[0;34m(args, kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_must_dispatch_in_python\u001b[39m(args, kwargs):\n\u001b[0;32m-> 1001\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpytree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_any\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_class_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFakeScriptObject\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/msc-thesis/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1230\u001b[0m, in \u001b[0;36mtree_any\u001b[0;34m(pred, tree, is_leaf)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtree_any\u001b[39m(\n\u001b[1;32m   1225\u001b[0m     pred: Callable[[Any], \u001b[38;5;28mbool\u001b[39m],\n\u001b[1;32m   1226\u001b[0m     tree: PyTree,\n\u001b[1;32m   1227\u001b[0m     is_leaf: Optional[Callable[[PyTree], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1228\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1229\u001b[0m     flat_args \u001b[38;5;241m=\u001b[39m tree_iter(tree, is_leaf\u001b[38;5;241m=\u001b[39mis_leaf)\n\u001b[0;32m-> 1230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/msc-thesis/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:927\u001b[0m, in \u001b[0;36mtree_iter\u001b[0;34m(tree, is_leaf)\u001b[0m\n\u001b[1;32m    925\u001b[0m node_type \u001b[38;5;241m=\u001b[39m _get_node_type(tree)\n\u001b[1;32m    926\u001b[0m flatten_fn \u001b[38;5;241m=\u001b[39m SUPPORTED_NODES[node_type]\u001b[38;5;241m.\u001b[39mflatten_fn\n\u001b[0;32m--> 927\u001b[0m child_pytrees, _ \u001b[38;5;241m=\u001b[39m \u001b[43mflatten_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;66;03m# Recursively flatten the children\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m child_pytrees:\n",
      "File \u001b[0;32m~/github/msc-thesis/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:438\u001b[0m, in \u001b[0;36m_tuple_flatten\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_tuple_flatten\u001b[39m(d: Tuple[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[Any], Context]:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(d), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_tuple_flatten_with_keys\u001b[39m(\n\u001b[1;32m    443\u001b[0m     d: Tuple[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m    444\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[Tuple[KeyEntry, Any]], Context]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def compute_consumer_optimal_with_lagrangian(\n",
    "    rel_matrix: torch.Tensor,\n",
    "    k_rec: int,\n",
    "    producer_max_min_utility: float,\n",
    "    gamma: float,\n",
    "    lr_primal: float = 1e-2,\n",
    "    lr_dual: float = 1e-2,\n",
    "    max_epochs: int = 5000,\n",
    "    verbose: bool = False\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Primal-dual via explicit Lagrangian multipliers for mean consumer utility maximization.\n",
    "\n",
    "    Args:\n",
    "        rel_matrix: (n, m) tensor of relevances.\n",
    "        k_rec: number of producers per consumer.\n",
    "        producer_max_min_utility: U_max reference.\n",
    "        gamma: fraction of U_max for floor constraint.\n",
    "        lr_primal: learning rate for primal (allocations) optimizer.\n",
    "        lr_dual: learning rate for dual (multipliers) optimizer.\n",
    "        max_epochs: maximum training epochs.\n",
    "        verbose: print diagnostics every 500 epochs.\n",
    "\n",
    "    Returns:\n",
    "        allocations: (n, m) tensor in [0,1] approx binary selections.\n",
    "    \"\"\"\n",
    "    n, m = rel_matrix.shape\n",
    "\n",
    "    # Primal: allocations logits\n",
    "    logits = nn.Parameter(torch.zeros(n, m))\n",
    "\n",
    "    # Dual multipliers: alpha for equality (size n), beta for inequality (size m)\n",
    "    alpha = nn.Parameter(torch.zeros(n))       # unconstrained\n",
    "    beta = nn.Parameter(torch.zeros(m))        # will clamp to >=0\n",
    "\n",
    "    # Optimizers\n",
    "    opt_primal = optim.Adam([logits], lr=lr_primal)\n",
    "    opt_dual = optim.Adam([alpha, beta], lr=lr_dual)\n",
    "\n",
    "    # Precompute threshold for producer constraint\n",
    "    min_prod = gamma * producer_max_min_utility\n",
    "\n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        # Compute allocations via sigmoid\n",
    "        A = torch.sigmoid(logits)\n",
    "\n",
    "        # Compute objective (mean consumer utility)\n",
    "        util = (A * rel_matrix).sum(dim=1).mean()\n",
    "\n",
    "        # Constraints:\n",
    "        #   per-consumer: sum_j A_ij == k_rec  =>  ci = sum - k_rec\n",
    "        ci = A.sum(dim=1) - k_rec\n",
    "        #   per-producer: sum_i A_ij >= min_prod => gj = min_prod - sum\n",
    "        gj = min_prod - A.sum(dim=0)\n",
    "\n",
    "        # Lagrangian: maximize util subject to constraints\n",
    "        # We minimize L = -util + alpha^T ci + beta^T gj\n",
    "        L = -util + (alpha * ci).mean() + (beta * gj).mean()\n",
    "\n",
    "        # ---- Primal update (minimize L wrt logits) ----\n",
    "        opt_primal.zero_grad()\n",
    "        L.backward(retain_graph=True)\n",
    "        opt_primal.step()\n",
    "\n",
    "        # ---- Dual update (maximize L wrt alpha,beta) ----\n",
    "        # we perform gradient ascent by minimizing -L\n",
    "        opt_dual.zero_grad()\n",
    "        dual_loss = -L\n",
    "        dual_loss.backward()\n",
    "        opt_dual.step()\n",
    "\n",
    "        # Enforce beta >= 0\n",
    "        with torch.no_grad():\n",
    "            beta.clamp_(min=0.0)\n",
    "\n",
    "        if verbose and epoch % 500 == 0:\n",
    "            with torch.no_grad():\n",
    "                min_c = ci.abs().max().item()\n",
    "                min_p = A.sum(dim=0).min().item()\n",
    "                print(f\"Epoch {epoch}: util={util.item():.4f}, max|ci|={min_c:.4f}, min_prod={min_p:.4f}\")\n",
    "\n",
    "    # Final allocations\n",
    "    return torch.sigmoid(logits).detach()\n",
    "\n",
    "allocations = compute_consumer_optimal_with_lagrangian(\n",
    "    rel_matrix=torch.tensor(sampled_matrix),\n",
    "    k_rec=10,\n",
    "    producer_max_min_utility=10,\n",
    "    gamma=0.5,\n",
    "    lr_primal=1e-2,\n",
    "    lr_dual=1e-2,\n",
    "    max_epochs=100000,\n",
    "    verbose=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "99c53024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvar_util(\n",
    "    rel_matrix: torch.Tensor,\n",
    "    allocations: torch.Tensor,\n",
    "    group_assignments: torch.Tensor,\n",
    "    k_rec: int,\n",
    "    rho: torch.Tensor,\n",
    "    alpha: float,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Vectorized, fully-differentiable CVaRâ€style objective over groups.\n",
    "    \"\"\"\n",
    "    # 1) Greedy topâ€k sum per example\n",
    "    greedy_allocs = rel_matrix.topk(k_rec, dim=1).values.sum(dim=1)  # (N,)\n",
    "\n",
    "    eps = 1e-8\n",
    "    loss_per_item = 1 - allocations / (greedy_allocs + eps)  # (N,)\n",
    "\n",
    "    # 3) Remap group IDs to 0â€¦Gâˆ’1\n",
    "    unique_groups, inverse = torch.unique(group_assignments, return_inverse=True)\n",
    "    G = unique_groups.numel()\n",
    "\n",
    "    # 4) Sum losses and counts per group via scatter_add_\n",
    "    device = rel_matrix.device\n",
    "    dtype = loss_per_item.dtype\n",
    "    sum_losses = torch.zeros(G, device=device, dtype=dtype).scatter_add_(0, inverse, loss_per_item)\n",
    "    counts = torch.zeros(G, device=device, dtype=dtype).scatter_add_(\n",
    "        0, inverse, torch.ones_like(loss_per_item)\n",
    "    )\n",
    "    norm_losses = sum_losses / (counts + eps)\n",
    "\n",
    "    # 5) CVaR objective\n",
    "    rho_clamped = torch.clamp(rho, min=0.0)\n",
    "    excess = torch.relu(norm_losses - rho_clamped).sum()\n",
    "    cvar_obj = rho_clamped + excess / ((1 - alpha) * G)\n",
    "\n",
    "    return cvar_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "169b2963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500: util=9.1009, max|ci|=0.2335, min_prod=10.2269\n",
      "Epoch 1000: util=6.0822, max|ci|=3.1755, min_prod=6.8299\n",
      "Epoch 1500: util=5.9762, max|ci|=3.2986, min_prod=6.7023\n",
      "Epoch 2000: util=7.1862, max|ci|=1.9355, min_prod=8.0394\n",
      "Epoch 2500: util=8.1647, max|ci|=0.8273, min_prod=9.1013\n",
      "Epoch 3000: util=8.5212, max|ci|=0.4252, min_prod=9.4566\n",
      "Epoch 3500: util=8.6877, max|ci|=0.2386, min_prod=9.5868\n",
      "Epoch 4000: util=8.7788, max|ci|=0.1374, min_prod=9.6172\n",
      "Epoch 4500: util=8.8313, max|ci|=0.0803, min_prod=9.5853\n",
      "Epoch 5000: util=8.8630, max|ci|=0.0473, min_prod=9.5061\n",
      "Epoch 5500: util=8.8832, max|ci|=0.0281, min_prod=9.3848\n",
      "Epoch 6000: util=8.8973, max|ci|=0.0168, min_prod=9.2206\n",
      "Epoch 6500: util=8.9085, max|ci|=0.0101, min_prod=9.0098\n",
      "Epoch 7000: util=8.9186, max|ci|=0.0060, min_prod=8.7465\n",
      "Epoch 7500: util=8.9291, max|ci|=0.0036, min_prod=8.4242\n",
      "Epoch 8000: util=8.9410, max|ci|=0.0022, min_prod=8.0368\n",
      "Epoch 8500: util=8.9553, max|ci|=0.0013, min_prod=7.5801\n",
      "Epoch 9000: util=8.9729, max|ci|=0.0014, min_prod=7.0535\n",
      "Epoch 9500: util=8.9949, max|ci|=0.0020, min_prod=6.4619\n",
      "Epoch 10000: util=9.0221, max|ci|=0.0021, min_prod=5.8178\n",
      "Epoch 10500: util=9.0545, max|ci|=0.0017, min_prod=5.1408\n",
      "Epoch 11000: util=9.0905, max|ci|=0.0017, min_prod=4.9933\n",
      "Epoch 11500: util=9.1264, max|ci|=0.0014, min_prod=4.9952\n",
      "Epoch 12000: util=9.1621, max|ci|=0.0012, min_prod=4.9957\n",
      "Epoch 12500: util=9.1950, max|ci|=0.0010, min_prod=4.9966\n",
      "Epoch 13000: util=9.2236, max|ci|=0.0010, min_prod=4.9970\n",
      "Epoch 13500: util=9.2479, max|ci|=0.0011, min_prod=4.9976\n",
      "Epoch 14000: util=9.2673, max|ci|=0.0013, min_prod=4.9981\n",
      "Epoch 14500: util=9.2842, max|ci|=0.0008, min_prod=4.9984\n",
      "Epoch 15000: util=9.2982, max|ci|=0.0014, min_prod=4.9975\n",
      "Epoch 15500: util=9.3104, max|ci|=0.0022, min_prod=4.9969\n",
      "Epoch 16000: util=9.3201, max|ci|=0.0024, min_prod=4.9959\n",
      "Epoch 16500: util=9.3281, max|ci|=0.0042, min_prod=4.9975\n",
      "Epoch 17000: util=9.3342, max|ci|=0.0029, min_prod=4.9970\n",
      "Epoch 17500: util=9.3388, max|ci|=0.0043, min_prod=4.9964\n",
      "Epoch 18000: util=9.3418, max|ci|=0.0033, min_prod=4.9958\n",
      "Epoch 18500: util=9.3439, max|ci|=0.0041, min_prod=4.9962\n",
      "Epoch 19000: util=9.3456, max|ci|=0.0026, min_prod=4.9967\n",
      "Epoch 19500: util=9.3467, max|ci|=0.0034, min_prod=4.9981\n",
      "Epoch 20000: util=9.3471, max|ci|=0.0037, min_prod=4.9971\n",
      "Epoch 20500: util=9.3478, max|ci|=0.0031, min_prod=4.9974\n",
      "Epoch 21000: util=9.3482, max|ci|=0.0035, min_prod=4.9978\n",
      "Epoch 21500: util=9.3483, max|ci|=0.0031, min_prod=4.9971\n",
      "Epoch 22000: util=9.3484, max|ci|=0.0020, min_prod=4.9989\n",
      "Epoch 22500: util=9.3483, max|ci|=0.0026, min_prod=4.9983\n",
      "Epoch 23000: util=9.3484, max|ci|=0.0026, min_prod=4.9979\n",
      "Epoch 23500: util=9.3484, max|ci|=0.0030, min_prod=4.9979\n",
      "Epoch 24000: util=9.3485, max|ci|=0.0022, min_prod=4.9986\n",
      "Epoch 24500: util=9.3486, max|ci|=0.0017, min_prod=4.9982\n",
      "Epoch 25000: util=9.3485, max|ci|=0.0027, min_prod=4.9981\n",
      "Epoch 25500: util=9.3485, max|ci|=0.0022, min_prod=4.9986\n",
      "Epoch 26000: util=9.3487, max|ci|=0.0031, min_prod=4.9991\n",
      "Epoch 26500: util=9.3486, max|ci|=0.0028, min_prod=4.9988\n",
      "Epoch 27000: util=9.3486, max|ci|=0.0025, min_prod=4.9985\n",
      "Epoch 27500: util=9.3486, max|ci|=0.0020, min_prod=4.9981\n",
      "Epoch 28000: util=9.3487, max|ci|=0.0028, min_prod=4.9989\n",
      "Epoch 28500: util=9.3487, max|ci|=0.0021, min_prod=4.9985\n",
      "Epoch 29000: util=9.3488, max|ci|=0.0034, min_prod=4.9993\n",
      "Epoch 29500: util=9.3487, max|ci|=0.0018, min_prod=4.9989\n",
      "Epoch 30000: util=9.3486, max|ci|=0.0025, min_prod=4.9986\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def compute_consumer_optimal_with_augmented_lagrangian(\n",
    "    rel_matrix: torch.Tensor,\n",
    "    k_rec: int,\n",
    "    producer_max_min_utility: float,\n",
    "    gamma: float,\n",
    "    lr_primal: float = 1e-2,\n",
    "    lr_dual: float = 1e-2,\n",
    "    rho: float = 10.0,\n",
    "    max_epochs: int = 5000,\n",
    "    verbose: bool = False\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Augmented Lagrangian primal-dual solver:\n",
    "      maximize mean utility under sum_j A[i,j]=k_rec and sum_i A[i,j]>=gamma*U constraints.\n",
    "\n",
    "    Args:\n",
    "        rel_matrix: (n, m) tensor of relevances.\n",
    "        allocations: (n, m) tensor for storing allocation results.\n",
    "        group_assignments: (n,) tensor for consumer group assignments.\n",
    "        k_rec: per-consumer recommendation count.\n",
    "        producer_max_min_utility: U_max reference.\n",
    "        gamma: fraction of U_max floor.\n",
    "        lr_primal: LR for primal (alloc) Adam.\n",
    "        lr_dual: LR for dual ascent.\n",
    "        rho: penalty parameter for augmented terms.\n",
    "        max_epochs: training steps.\n",
    "        verbose: print diagnostics.\n",
    "    Returns:\n",
    "        A: (n, m) allocation matrix in [0,1].\n",
    "    \"\"\"\n",
    "    n, m = rel_matrix.shape\n",
    "    # primal logits\n",
    "    logits = nn.Parameter(torch.zeros(n, m))\n",
    "    # dual vars\n",
    "    alpha = torch.zeros(n, requires_grad=False)\n",
    "    beta  = torch.zeros(m, requires_grad=False)\n",
    "    min_prod = gamma * producer_max_min_utility\n",
    "\n",
    "    opt = optim.Adam([logits], lr=lr_primal)\n",
    "\n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        A = torch.sigmoid(logits)\n",
    "        # objective\n",
    "        util = (A * rel_matrix).sum(dim=1).mean()\n",
    "        # constraints residuals\n",
    "        ci = A.sum(dim=1) - k_rec                 # target zero\n",
    "        gj = torch.relu(min_prod - A.sum(dim=0))  # positive slack if violation\n",
    "\n",
    "        # augmented Lagrangian\n",
    "        L = -util + (alpha * ci).mean() + (beta * gj).mean() \\\n",
    "            + (rho/2)*(ci.pow(2).mean()) + (rho/2)*(gj.pow(2).mean())\n",
    "\n",
    "        opt.zero_grad()\n",
    "        L.backward()\n",
    "        # gradient step on logits\n",
    "        opt.step()\n",
    "        # project logits to encourage binarity (optional)\n",
    "        with torch.no_grad():\n",
    "            logits.clamp_(-5, 5)\n",
    "\n",
    "        # dual ascent on alpha, beta\n",
    "        with torch.no_grad():\n",
    "            alpha += lr_dual * ci\n",
    "            beta  += lr_dual * gj\n",
    "            beta.clamp_(min=0.0)\n",
    "\n",
    "        if verbose and epoch % 500 == 0:\n",
    "            with torch.no_grad():\n",
    "                max_ci = ci.abs().max().item()\n",
    "                min_prod_rec = (A.sum(dim=0)).min().item()\n",
    "                print(f\"Epoch {epoch}: util={util.item():.4f}, max|ci|={max_ci:.4f}, min_prod={min_prod_rec:.4f}\")\n",
    "\n",
    "    # final allocation\n",
    "    return torch.sigmoid(logits).detach()\n",
    "\n",
    "A = compute_consumer_optimal_with_augmented_lagrangian(\n",
    "    rel_matrix=torch.tensor(sampled_matrix),\n",
    "    k_rec=10,\n",
    "    producer_max_min_utility=10,\n",
    "    gamma=0.5,\n",
    "    lr_primal=1e-2,\n",
    "    lr_dual=1e-2,\n",
    "    rho=10.0,\n",
    "    max_epochs=30000,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1bbfe628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 10.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9., 10.,  9., 10.,  9.,\n",
       "         9.,  9., 10.,  9.,  9.,  9.,  9.,  8.,  9., 10.,  9.,  9.,  9.,  9.,\n",
       "         9., 10.,  9.,  9.,  9.,  9.,  8.,  9.,  9.,  9.,  9., 10.,  9.,  9.,\n",
       "         9.,  9.,  9., 10., 10.,  9.,  9., 10.,  9.,  9.,  9.,  9., 10.,  9.,\n",
       "        10., 10., 10.,  9., 10.,  9.,  9., 10.,  9.,  9., 10.,  9.,  9.,  9.,\n",
       "         9.,  9.,  9.,  9., 10., 10.,  9.,  9.,  9.,  9., 10.,  8.,  9.,  9.,\n",
       "         8., 10., 10.,  9.,  9., 10.,  9.,  9.,  9., 10.,  9.,  9., 10.,  8.,\n",
       "         9.,  9.])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.round().sum(axis=1)  # sum of all producers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d26e4a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500: cvar_loss=0.7080, max|ci|=0.3564, min_prod=10.2114\n",
      "Epoch 1000: cvar_loss=0.3854, max|ci|=3.1995, min_prod=6.8058\n",
      "Epoch 1500: cvar_loss=0.3990, max|ci|=3.3566, min_prod=6.6652\n",
      "Epoch 2000: cvar_loss=0.2820, max|ci|=2.0007, min_prod=8.0255\n",
      "Epoch 2500: cvar_loss=0.1858, max|ci|=0.8919, min_prod=9.1461\n",
      "Epoch 3000: cvar_loss=0.1484, max|ci|=0.4737, min_prod=9.5471\n",
      "Epoch 3500: cvar_loss=0.1304, max|ci|=0.2741, min_prod=9.7271\n",
      "Epoch 4000: cvar_loss=0.1204, max|ci|=0.1554, min_prod=9.8200\n",
      "Epoch 4500: cvar_loss=0.1129, max|ci|=0.0827, min_prod=9.8681\n",
      "Epoch 5000: cvar_loss=0.1089, max|ci|=0.1038, min_prod=9.8914\n",
      "Epoch 5500: cvar_loss=0.1032, max|ci|=0.1488, min_prod=9.8990\n",
      "Epoch 6000: cvar_loss=0.0990, max|ci|=0.1904, min_prod=9.8933\n",
      "Epoch 6500: cvar_loss=0.0946, max|ci|=0.2248, min_prod=9.8766\n",
      "Epoch 7000: cvar_loss=0.0898, max|ci|=0.2378, min_prod=9.8506\n",
      "Epoch 7500: cvar_loss=0.0849, max|ci|=0.2187, min_prod=9.8178\n",
      "Epoch 8000: cvar_loss=0.0816, max|ci|=0.1981, min_prod=9.7792\n",
      "Epoch 8500: cvar_loss=0.0790, max|ci|=0.1757, min_prod=9.7276\n",
      "Epoch 9000: cvar_loss=0.0755, max|ci|=0.1068, min_prod=9.6593\n",
      "Epoch 9500: cvar_loss=0.0733, max|ci|=0.0645, min_prod=9.5734\n",
      "Epoch 10000: cvar_loss=0.0702, max|ci|=0.0624, min_prod=9.4652\n",
      "Epoch 10500: cvar_loss=0.0676, max|ci|=0.0412, min_prod=9.3156\n",
      "Epoch 11000: cvar_loss=0.0654, max|ci|=0.0187, min_prod=9.1376\n",
      "Epoch 11500: cvar_loss=0.0620, max|ci|=0.0293, min_prod=8.9490\n",
      "Epoch 12000: cvar_loss=0.0589, max|ci|=0.0743, min_prod=8.7683\n",
      "Epoch 12500: cvar_loss=0.0579, max|ci|=0.0704, min_prod=8.5173\n",
      "Epoch 13000: cvar_loss=0.0568, max|ci|=0.0529, min_prod=8.1479\n",
      "Epoch 13500: cvar_loss=0.0552, max|ci|=0.0334, min_prod=7.6996\n",
      "Epoch 14000: cvar_loss=0.0529, max|ci|=0.0492, min_prod=7.2744\n",
      "Epoch 14500: cvar_loss=0.0514, max|ci|=0.0839, min_prod=6.9041\n",
      "Epoch 15000: cvar_loss=0.0510, max|ci|=0.0581, min_prod=6.5346\n",
      "Epoch 15500: cvar_loss=0.0475, max|ci|=0.0287, min_prod=6.1784\n",
      "Epoch 16000: cvar_loss=0.0465, max|ci|=0.0483, min_prod=5.8489\n",
      "Epoch 16500: cvar_loss=0.0448, max|ci|=0.0392, min_prod=5.5420\n",
      "Epoch 17000: cvar_loss=0.0429, max|ci|=0.0555, min_prod=5.2837\n",
      "Epoch 17500: cvar_loss=0.0425, max|ci|=0.0292, min_prod=4.9989\n",
      "Epoch 18000: cvar_loss=0.0401, max|ci|=0.0220, min_prod=5.0015\n",
      "Epoch 18500: cvar_loss=0.0401, max|ci|=0.0527, min_prod=4.9983\n",
      "Epoch 19000: cvar_loss=0.0394, max|ci|=0.0481, min_prod=4.9991\n",
      "Epoch 19500: cvar_loss=0.0384, max|ci|=0.0429, min_prod=4.9986\n",
      "Epoch 20000: cvar_loss=0.0371, max|ci|=0.0389, min_prod=4.9978\n",
      "Epoch 20500: cvar_loss=0.0362, max|ci|=0.0428, min_prod=5.0021\n",
      "Epoch 21000: cvar_loss=0.0352, max|ci|=0.0652, min_prod=5.0011\n",
      "Epoch 21500: cvar_loss=0.0344, max|ci|=0.0499, min_prod=4.9994\n",
      "Epoch 22000: cvar_loss=0.0358, max|ci|=0.0582, min_prod=5.0007\n",
      "Epoch 22500: cvar_loss=0.0344, max|ci|=0.0802, min_prod=4.9942\n",
      "Epoch 23000: cvar_loss=0.0326, max|ci|=0.0610, min_prod=5.0040\n",
      "Epoch 23500: cvar_loss=0.0334, max|ci|=0.0416, min_prod=5.0002\n",
      "Epoch 24000: cvar_loss=0.0315, max|ci|=0.0563, min_prod=4.9997\n",
      "Epoch 24500: cvar_loss=0.0320, max|ci|=0.0499, min_prod=5.0005\n",
      "Epoch 25000: cvar_loss=0.0341, max|ci|=0.0553, min_prod=4.9953\n",
      "Epoch 25500: cvar_loss=0.0309, max|ci|=0.0429, min_prod=5.0002\n",
      "Epoch 26000: cvar_loss=0.0300, max|ci|=0.0228, min_prod=5.0004\n",
      "Epoch 26500: cvar_loss=0.0294, max|ci|=0.0668, min_prod=4.9972\n",
      "Epoch 27000: cvar_loss=0.0299, max|ci|=0.0574, min_prod=5.0068\n",
      "Epoch 27500: cvar_loss=0.0289, max|ci|=0.0700, min_prod=5.0081\n",
      "Epoch 28000: cvar_loss=0.0283, max|ci|=0.0398, min_prod=5.0074\n",
      "Epoch 28500: cvar_loss=0.0286, max|ci|=0.0403, min_prod=5.0024\n",
      "Epoch 29000: cvar_loss=0.0284, max|ci|=0.0509, min_prod=4.9994\n",
      "Epoch 29500: cvar_loss=0.0279, max|ci|=0.0756, min_prod=5.0028\n",
      "Epoch 30000: cvar_loss=0.0270, max|ci|=0.0574, min_prod=5.0067\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def compute_consumer_optimal_with_augmented_lagrangian_cvar(\n",
    "    rel_matrix: torch.Tensor,\n",
    "    k_rec: int,\n",
    "    producer_max_min_utility: float,\n",
    "    gamma: float,\n",
    "    group_assignments: torch.Tensor,\n",
    "    alpha: float,\n",
    "    lr_primal: float = 1e-2,\n",
    "    lr_dual: float = 1e-2,\n",
    "    rho: float = 10.0,\n",
    "    max_epochs: int = 5000,\n",
    "    verbose: bool = False\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Augmented Lagrangian solver with CVaR group objective:\n",
    "      minimizes cvar_util + constraints via Lagrangian multipliers.\n",
    "    \"\"\"\n",
    "    n, m = rel_matrix.shape\n",
    "    # primal logits\n",
    "    logits = nn.Parameter(torch.zeros(n, m))\n",
    "    # dual vars (no grad for multipliers)\n",
    "    alpha_user = torch.zeros(n, requires_grad=False)\n",
    "    beta_prod  = torch.zeros(m, requires_grad=False)\n",
    "    min_prod = gamma * producer_max_min_utility\n",
    "\n",
    "    log_rho = nn.Parameter(torch.log(torch.tensor(0.0)))\n",
    "    opt = optim.Adam([logits, log_rho], lr=lr_primal)\n",
    "\n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        A = torch.sigmoid(logits)\n",
    "        consumer_allocations = (A * rel_matrix).sum(dim=1)\n",
    "        # Compute CVaR loss over groups\n",
    "        rho_val = torch.exp(log_rho)\n",
    "\n",
    "        cvar_loss = cvar_util(rel_matrix, consumer_allocations, group_assignments, k_rec, rho_val, alpha)\n",
    "        # Constraint residuals\n",
    "        ci = A.sum(dim=1) - k_rec\n",
    "        gj = torch.relu(min_prod - A.sum(dim=0))\n",
    "\n",
    "        # Augmented Lagrangian\n",
    "        L = cvar_loss + (alpha_user * ci).mean() + (beta_prod * gj).mean() \\\n",
    "            + (rho/2)*(ci.pow(2).mean()) + (rho/2)*(gj.pow(2).mean())\n",
    "\n",
    "        # Primal step\n",
    "        opt.zero_grad()\n",
    "        L.backward()\n",
    "        opt.step()\n",
    "        with torch.no_grad():\n",
    "            logits.clamp_(-5, 5)\n",
    "            log_rho.clamp_(min=torch.log(torch.tensor(1e-3)), max=torch.log(torch.tensor(1e3)))\n",
    "\n",
    "\n",
    "        # Dual ascent\n",
    "        with torch.no_grad():\n",
    "            alpha_user += lr_dual * ci\n",
    "            beta_prod  += lr_dual * gj\n",
    "            beta_prod.clamp_(min=0.0)\n",
    "\n",
    "        if verbose and epoch % 500 == 0:\n",
    "            with torch.no_grad():\n",
    "                max_ci = ci.abs().max().item()\n",
    "                min_prod_rec = A.sum(dim=0).min().item()\n",
    "                print(f\"Epoch {epoch}: cvar_loss={cvar_loss.item():.4f}, \"\n",
    "                      f\"max|ci|={max_ci:.4f}, min_prod={min_prod_rec:.4f}\")\n",
    "\n",
    "    return torch.sigmoid(logits).detach()\n",
    "\n",
    "\n",
    "A = compute_consumer_optimal_with_augmented_lagrangian_cvar(\n",
    "    rel_matrix=torch.tensor(sampled_matrix),\n",
    "    group_assignments=torch.tensor(group_assignments),\n",
    "    alpha=0.95,\n",
    "    k_rec=10,\n",
    "    producer_max_min_utility=10,\n",
    "    gamma=0.5,\n",
    "    lr_primal=1e-2,\n",
    "    lr_dual=1e-2,\n",
    "    rho=10.0,\n",
    "    max_epochs=30000,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "02b6ee23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500: util=0.7602, max|ci|=0.2951, min_prod=0.0000\n",
      "Epoch 1000: util=0.5435, max|ci|=0.2810, min_prod=0.0000\n",
      "Epoch 1500: util=0.4055, max|ci|=0.2107, min_prod=0.0000\n",
      "Epoch 2000: util=0.3104, max|ci|=0.1993, min_prod=0.0000\n",
      "Epoch 2500: util=0.2409, max|ci|=0.1444, min_prod=0.0000\n",
      "Epoch 3000: util=0.1833, max|ci|=0.1944, min_prod=0.0000\n",
      "Epoch 3500: util=0.1453, max|ci|=0.1533, min_prod=0.0000\n",
      "Epoch 4000: util=0.1152, max|ci|=0.1327, min_prod=0.0000\n",
      "Epoch 4500: util=0.0945, max|ci|=0.1097, min_prod=0.0000\n",
      "Epoch 5000: util=0.0776, max|ci|=0.1201, min_prod=0.0000\n",
      "Epoch 5500: util=0.0669, max|ci|=0.0914, min_prod=0.0000\n",
      "Epoch 6000: util=0.0549, max|ci|=0.1090, min_prod=0.0000\n",
      "Epoch 6500: util=0.0482, max|ci|=0.0823, min_prod=0.0000\n",
      "Epoch 7000: util=0.0434, max|ci|=0.0602, min_prod=0.0000\n",
      "Epoch 7500: util=0.0368, max|ci|=0.0874, min_prod=1.0000\n",
      "Epoch 8000: util=0.0331, max|ci|=0.0980, min_prod=1.0000\n",
      "Epoch 8500: util=0.0317, max|ci|=0.0559, min_prod=1.0000\n",
      "Epoch 9000: util=0.0295, max|ci|=0.0754, min_prod=2.0000\n",
      "Epoch 9500: util=0.0276, max|ci|=0.0860, min_prod=2.0000\n",
      "Epoch 10000: util=0.0263, max|ci|=0.0515, min_prod=2.0000\n",
      "Epoch 10500: util=0.0248, max|ci|=0.0652, min_prod=2.0000\n",
      "Epoch 11000: util=0.0229, max|ci|=0.0756, min_prod=3.0000\n",
      "Epoch 11500: util=0.0228, max|ci|=0.0421, min_prod=3.0000\n",
      "Epoch 12000: util=0.0213, max|ci|=0.0564, min_prod=3.0000\n",
      "Epoch 12500: util=0.0210, max|ci|=0.0666, min_prod=3.0000\n",
      "Epoch 13000: util=0.0211, max|ci|=0.0314, min_prod=3.0000\n",
      "Epoch 13500: util=0.0195, max|ci|=0.0357, min_prod=3.0000\n",
      "Epoch 14000: util=0.0192, max|ci|=0.0605, min_prod=3.0000\n",
      "Epoch 14500: util=0.0184, max|ci|=0.0316, min_prod=3.0000\n",
      "Epoch 15000: util=0.0181, max|ci|=0.0561, min_prod=3.0000\n",
      "Epoch 15500: util=0.0182, max|ci|=0.0279, min_prod=4.0000\n",
      "Epoch 16000: util=0.0170, max|ci|=0.0522, min_prod=4.0000\n",
      "Epoch 16500: util=0.0179, max|ci|=0.0246, min_prod=4.0000\n",
      "Epoch 17000: util=0.0166, max|ci|=0.0485, min_prod=4.0000\n",
      "Epoch 17500: util=0.0171, max|ci|=0.0299, min_prod=4.0000\n",
      "Epoch 18000: util=0.0160, max|ci|=0.0306, min_prod=4.0000\n",
      "Epoch 18500: util=0.0159, max|ci|=0.0388, min_prod=4.0000\n",
      "Epoch 19000: util=0.0158, max|ci|=0.0267, min_prod=4.0000\n",
      "Epoch 19500: util=0.0155, max|ci|=0.0254, min_prod=4.0000\n",
      "Epoch 20000: util=0.0156, max|ci|=0.0361, min_prod=4.0000\n",
      "Epoch 20500: util=0.0155, max|ci|=0.0199, min_prod=4.0000\n",
      "Epoch 21000: util=0.0158, max|ci|=0.0216, min_prod=4.0000\n",
      "Epoch 21500: util=0.0161, max|ci|=0.0208, min_prod=4.0000\n",
      "Epoch 22000: util=0.0147, max|ci|=0.0218, min_prod=4.0000\n",
      "Epoch 22500: util=0.0147, max|ci|=0.0215, min_prod=4.0000\n",
      "Epoch 23000: util=0.0146, max|ci|=0.0203, min_prod=4.0000\n",
      "Epoch 23500: util=0.0148, max|ci|=0.0140, min_prod=4.0000\n",
      "Epoch 24000: util=0.0152, max|ci|=0.0149, min_prod=4.0000\n",
      "Epoch 24500: util=0.0141, max|ci|=0.0132, min_prod=4.0000\n",
      "Epoch 25000: util=0.0141, max|ci|=0.0186, min_prod=4.0000\n",
      "Epoch 25500: util=0.0140, max|ci|=0.0208, min_prod=4.0000\n",
      "Epoch 26000: util=0.0145, max|ci|=0.0092, min_prod=4.0000\n",
      "Epoch 26500: util=0.0139, max|ci|=0.0107, min_prod=4.0000\n",
      "Epoch 27000: util=0.0142, max|ci|=0.0103, min_prod=4.0000\n",
      "Epoch 27500: util=0.0133, max|ci|=0.0271, min_prod=4.0000\n",
      "Epoch 28000: util=0.0133, max|ci|=0.0153, min_prod=4.0000\n",
      "Epoch 28500: util=0.0149, max|ci|=0.0172, min_prod=4.0000\n",
      "Epoch 29000: util=0.0132, max|ci|=0.0112, min_prod=4.0000\n",
      "Epoch 29500: util=0.0130, max|ci|=0.0189, min_prod=4.0000\n",
      "Epoch 30000: util=0.0131, max|ci|=0.0203, min_prod=4.0000\n",
      "Epoch 30500: util=0.0131, max|ci|=0.0119, min_prod=4.0000\n",
      "Epoch 31000: util=0.0128, max|ci|=0.0204, min_prod=4.0000\n",
      "Epoch 31500: util=0.0128, max|ci|=0.0085, min_prod=4.0000\n",
      "Epoch 32000: util=0.0131, max|ci|=0.0076, min_prod=4.0000\n",
      "Epoch 32500: util=0.0125, max|ci|=0.0203, min_prod=4.0000\n",
      "Epoch 33000: util=0.0128, max|ci|=0.0082, min_prod=4.0000\n",
      "Epoch 33500: util=0.0125, max|ci|=0.0197, min_prod=4.0000\n",
      "Epoch 34000: util=0.0127, max|ci|=0.0125, min_prod=4.0000\n",
      "Epoch 34500: util=0.0133, max|ci|=0.0056, min_prod=4.0000\n",
      "Epoch 35000: util=0.0126, max|ci|=0.0084, min_prod=4.0000\n",
      "Epoch 35500: util=0.0128, max|ci|=0.0035, min_prod=4.0000\n",
      "Epoch 36000: util=0.0125, max|ci|=0.0112, min_prod=4.0000\n",
      "Epoch 36500: util=0.0130, max|ci|=0.0035, min_prod=4.0000\n",
      "Epoch 37000: util=0.0125, max|ci|=0.0057, min_prod=4.0000\n",
      "Epoch 37500: util=0.0129, max|ci|=0.0032, min_prod=4.0000\n",
      "Epoch 38000: util=0.0123, max|ci|=0.0077, min_prod=4.0000\n",
      "Epoch 38500: util=0.0130, max|ci|=0.0052, min_prod=4.0000\n",
      "Epoch 39000: util=0.0126, max|ci|=0.0078, min_prod=4.0000\n",
      "Epoch 39500: util=0.0124, max|ci|=0.0172, min_prod=4.0000\n",
      "Epoch 40000: util=0.0131, max|ci|=0.0144, min_prod=4.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def compute_consumer_optimal_with_augmented_lagrangian_cvar(\n",
    "    rel_matrix: torch.Tensor,\n",
    "    group_assignments: torch.Tensor,\n",
    "    alpha_cvar: float,\n",
    "    k_rec: int,\n",
    "    producer_max_min_utility: float,\n",
    "    gamma: float,\n",
    "    lr_primal: float = 1e-2,\n",
    "    lr_dual: float = 1e-2,\n",
    "    rho: float = 10.0,\n",
    "    max_epochs: int = 5000,\n",
    "    verbose: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Augmented Lagrangian primal-dual solver:\n",
    "      maximize mean utility under sum_j A[i,j]=k_rec and sum_i A[i,j]>=gamma*U constraints.\n",
    "\n",
    "    Args:\n",
    "        rel_matrix: (n, m) tensor of relevances.\n",
    "        allocations: (n, m) tensor for storing allocation results.\n",
    "        group_assignments: (n,) tensor for consumer group assignments.\n",
    "        k_rec: per-consumer recommendation count.\n",
    "        producer_max_min_utility: U_max reference.\n",
    "        gamma: fraction of U_max floor.\n",
    "        lr_primal: LR for primal (alloc) Adam.\n",
    "        lr_dual: LR for dual ascent.\n",
    "        rho: penalty parameter for augmented terms.\n",
    "        max_epochs: training steps.\n",
    "        verbose: print diagnostics.\n",
    "    Returns:\n",
    "        A: (n, m) allocation matrix in [0,1].\n",
    "    \"\"\"\n",
    "    class CVaRModule(nn.Module):\n",
    "        def __init__(self, n: int, m: int):\n",
    "            super().__init__()\n",
    "            self.rho_cvar = nn.Parameter(torch.zeros(1))\n",
    "            self.logits = nn.Parameter(torch.zeros(n, m))\n",
    "\n",
    "    model = CVaRModule(rel_matrix.shape[0], rel_matrix.shape[1])\n",
    "\n",
    "    n, m = rel_matrix.shape\n",
    "    # primal logits\n",
    "    # dual vars\n",
    "    alpha = torch.zeros(n, requires_grad=False)\n",
    "    beta  = torch.zeros(m, requires_grad=False)\n",
    "    min_prod = gamma * producer_max_min_utility\n",
    "\n",
    "\n",
    "    opt = optim.AdamW(model.parameters(), lr=lr_primal, weight_decay=1e-4)\n",
    "\n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        A = torch.sigmoid(model.logits / 0.1)\n",
    "        consumer_allocations = (A * rel_matrix).sum(dim=1)\n",
    "        # objective\n",
    "        util = cvar_util(\n",
    "            rel_matrix, consumer_allocations, group_assignments, k_rec, model.rho_cvar, alpha_cvar\n",
    "        )\n",
    "        ci = A.sum(dim=1) - k_rec\n",
    "        gj = torch.relu(min_prod - A.sum(dim=0))\n",
    "\n",
    "        # augmented Lagrangian\n",
    "        loss = util + (alpha * ci).mean() + (beta * gj).mean() \\\n",
    "            + (rho/2)*(ci.pow(2).mean()) + (rho/2)*(gj.pow(2).mean())\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            model.parameters(), max_norm=3.0\n",
    "        )\n",
    "        opt.step()\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            alpha += lr_dual * ci\n",
    "            beta  += lr_dual * gj\n",
    "            beta.clamp_(min=0.0)\n",
    "\n",
    "\n",
    "        if verbose and epoch % 500 == 0:\n",
    "            with torch.no_grad():\n",
    "                max_ci = ci.abs().max().item()\n",
    "                min_prod_rec = (A.round().sum(axis=0)).min().item()\n",
    "                print(f\"Epoch {epoch}: util={util.item():.4f}, max|ci|={max_ci:.4f}, min_prod={min_prod_rec:.4f}\")\n",
    "\n",
    "    return torch.sigmoid(model.logits).detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "sampled_matrix, consumer_ids, group_assignments = sample_data_for_group(\n",
    "    n_consumers=100,\n",
    "    n_producers=100,\n",
    "    groups_map=GROUPS_MAP,\n",
    "    group_key=\"top_category\",\n",
    "    data=REL_MATRIX,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "\n",
    "A = compute_consumer_optimal_with_augmented_lagrangian_cvar(\n",
    "    rel_matrix=torch.tensor(sampled_matrix),\n",
    "    group_assignments=torch.tensor(group_assignments),\n",
    "    alpha_cvar=0.95,\n",
    "    k_rec=25,\n",
    "    producer_max_min_utility=10,\n",
    "    gamma=0.5,\n",
    "    lr_primal=1e-3,\n",
    "    lr_dual=1e-3,\n",
    "    rho=10.0,\n",
    "    max_epochs=40000,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "86bb97fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  5.,  6., 29.,  5., 19., 53.,  5., 10., 50.,  5., 20.,  5.,\n",
       "       30., 10., 86., 14.,  5., 77.,  5., 98.,  5., 93.,  5., 93., 68.,\n",
       "        5., 38.,  5.,  5.,  5.,  5., 96.,  5.,  5.,  5., 79.,  5.,  5.,\n",
       "       70.,  5.,  5., 98., 44.,  5., 54.,  5.,  5., 71.,  5.,  5.,  5.,\n",
       "       83.,  5., 95., 76.,  5.,  5.,  5.,  5.,  5., 35., 90.,  5.,  5.,\n",
       "       45.,  5., 29.,  5.,  5.,  5., 31.,  5.,  5.,  6.,  8., 95.,  5.,\n",
       "       19.,  5., 98.,  4., 81.,  5.,  5.,  5.,  5.,  5.,  5., 15.,  4.,\n",
       "       48.,  5.,  9., 16.,  5.,  5.,  5.,  5., 31.], dtype=float32)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.round().sum(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

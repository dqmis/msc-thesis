{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from torch import nn\n",
    "from sklearn import model_selection\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x106a878f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self,  root: str = \"data\", data: pd.DataFrame | None = None, download: bool = False):\n",
    "        self._root = Path(root)\n",
    "        self._path = self._root / \"ml-100k\"\n",
    "\n",
    "        self._data = data if data is not None else self._load_data(download)\n",
    "\n",
    "        self._genre_lbl_enc = preprocessing.LabelEncoder()\n",
    "        self._genre_lbl_enc.fit(self._data[\"genre\"])\n",
    "\n",
    "        self.n_groups = self._genre_lbl_enc.classes_.shape[0]\n",
    "        self._group_counts = torch.tensor(self._data[\"genre\"].value_counts().sort_index().values)\n",
    "\n",
    "        self.group_str = {i: genre for i, genre in enumerate(self._genre_lbl_enc.classes_)}\n",
    "\n",
    "    def group_counts(self):\n",
    "        return self._group_counts\n",
    "\n",
    "    def _load_data(self, download: bool) -> pd.DataFrame:\n",
    "        if not self._path.exists():\n",
    "            if not download:\n",
    "                raise FileNotFoundError(f\"{self._path} not found\")\n",
    "            else:\n",
    "                self._download()\n",
    "\n",
    "        data = pd.read_csv(\n",
    "            self._path / \"u.data\",\n",
    "            sep=\"\\t\",\n",
    "            header=None,\n",
    "            names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"],\n",
    "        )\n",
    "        data.drop(columns=[\"timestamp\"], inplace=True)\n",
    "\n",
    "        item_data = pd.read_csv(\n",
    "            self._path / \"u.item\",\n",
    "            sep=\"|\",\n",
    "            header=None,\n",
    "            encoding=\"ISO-8859-1\",\n",
    "            names=[\"item_id\", \"title\", \"release_date\", \"video_release_date\", \"IMDb_URL\", \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"],\n",
    "        )\n",
    "\n",
    "        def get_random_genre(row):\n",
    "            genres = row[6:].index[row[6:] == 1].tolist()  # Get list of genres where value is 1\n",
    "            if genres: #Check if the list is not empty\n",
    "                return np.random.choice(genres) #Return a random genre from the list\n",
    "            else:\n",
    "                return \"Unknown\" # Or handle the case where no genre is found\n",
    "\n",
    "        item_data[\"genre\"] = item_data.apply(get_random_genre, axis=1)\n",
    "\n",
    "        item_data = item_data[[\"item_id\", \"genre\"]]\n",
    "        data = data.merge(item_data, on=\"item_id\")\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def _download(self):\n",
    "        _URL = \"https://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "            with requests.get(_URL, stream=True) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(tmpdirname + \"/ml-100k.zip\", \"wb\") as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "\n",
    "            with zipfile.ZipFile(tmpdirname + \"/ml-100k.zip\", \"r\") as zip_ref:\n",
    "                zip_ref.extractall(self._root)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self._data.iloc[idx]\n",
    "\n",
    "        genre_id = self._genre_lbl_enc.transform([row[\"genre\"]])\n",
    "\n",
    "        return {\n",
    "            \"users\": torch.tensor(row[\"user_id\"], dtype=torch.long),\n",
    "            \"items\": torch.tensor(row[\"item_id\"], dtype=torch.long),\n",
    "            \"ratings\": torch.tensor(row[\"rating\"], dtype=torch.float),\n",
    "            \"genre_mask\": nn.functional.one_hot(torch.tensor(genre_id, dtype=torch.long), num_classes=len(self._genre_lbl_enc.classes_))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationSystemModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users,\n",
    "        num_movies,\n",
    "        embedding_size=256,\n",
    "        hidden_dim=256,\n",
    "        dropout_rate=0.2,\n",
    "    ):\n",
    "        super(RecommendationSystemModel, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Embedding layers\n",
    "        self.user_embedding = nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.embedding_size\n",
    "        )\n",
    "        self.movie_embedding = nn.Embedding(\n",
    "            num_embeddings=self.num_movies, embedding_dim=self.embedding_size\n",
    "        )\n",
    "\n",
    "        # Hidden layers\n",
    "        self.fc1 = nn.Linear(2 * self.embedding_size, self.hidden_dim)\n",
    "        self.fc2 = nn.Linear(self.hidden_dim, 1)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, users, movies):\n",
    "        # Embeddings\n",
    "        user_embedded = self.user_embedding(users)\n",
    "        movie_embedded = self.movie_embedding(movies)\n",
    "\n",
    "        # Concatenate user and movie embeddings\n",
    "        combined = torch.cat([user_embedded, movie_embedded], dim=1)\n",
    "\n",
    "        # Pass through hidden layers with ReLU activation and dropout\n",
    "        x = self.relu(self.fc1(combined))\n",
    "        x = self.dropout(x)\n",
    "        output = self.fc2(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = MovieLensDataset(download=True)._data\n",
    "# remove Unknown genre\n",
    "df = df[df.genre != \"Unknown\"]\n",
    "\n",
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_movie = preprocessing.LabelEncoder()\n",
    "\n",
    "df.user_id = lbl_user.fit_transform(df.user_id.values)\n",
    "df.item_id = lbl_movie.fit_transform(df.item_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = model_selection.train_test_split(\n",
    "    df, test_size=0.1, random_state=3, stratify=df.rating.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling down all genres except for Drama\n",
    "df_train = pd.concat([df_train[df_train.genre == \"Drama\"], df_train[df_train.genre != \"Drama\"].sample(frac=0.1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Drama          23264\n",
       "Comedy          1595\n",
       "Thriller         808\n",
       "Romance          697\n",
       "Adventure        648\n",
       "Action           648\n",
       "Sci-Fi           417\n",
       "Crime            296\n",
       "Children         295\n",
       "War              279\n",
       "Horror           255\n",
       "Musical          184\n",
       "Western          151\n",
       "Mystery          123\n",
       "Animation        104\n",
       "Documentary       67\n",
       "Film-Noir         63\n",
       "Fantasy           43\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = MovieLensDataset(data=df_train)\n",
    "valid_dataset = MovieLensDataset(data=df_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_per_group(sq_err, mask, risk_groups: list[int] | None = None) -> torch.Tensor:\n",
    "    mask_means = mask.float().mean(dim=0)\n",
    "    if risk_groups is not None:\n",
    "        mask_means = mask_means * torch.tensor([1 if i in risk_groups else 0 for i in range(mask_means.shape[0])], device=mask_means.device)\n",
    "\n",
    "    mask = mask * mask_means\n",
    "    mask = mask.detach()\n",
    "\n",
    "    loss = sq_err + 1e-8\n",
    "    loss = loss.view(-1, 1) * mask\n",
    "\n",
    "    # remove columns with all zeros\n",
    "    # loss = loss[:, mask.sum(dim=0) > 0]\n",
    "    loss = loss ** 2\n",
    "\n",
    "    return loss.sum(dim=0).mean()\n",
    "\n",
    "sq_err_ls = []\n",
    "lpg_ls = []\n",
    "\n",
    "\n",
    "def loss_func(output, target, mask, lmbd: float, risk_groups: list[int] | None = None) -> torch.Tensor:\n",
    "    sq_err = torch.pow(output - target, 2)\n",
    "    lpg = loss_per_group(sq_err, mask, risk_groups)\n",
    "\n",
    "    sq_err_ls.append(sq_err.mean().item())\n",
    "    lpg_ls.append(lpg.item())\n",
    "\n",
    "    f = sq_err.mean() * (1 - lmbd) + lpg * lmbd\n",
    "    return f\n",
    "\n",
    "#loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/02 | Step: 1600/29251 | Avg Loss: 0.537972047"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 29251 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/02 | Step: 29251/29251 | Avg Loss: 0.134126921"
     ]
    }
   ],
   "source": [
    "recommendation_model = RecommendationSystemModel(\n",
    "    num_users=len(lbl_user.classes_),\n",
    "    num_movies=len(lbl_movie.classes_),\n",
    "    embedding_size=128,\n",
    "    hidden_dim=256,\n",
    "    dropout_rate=0.1,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(recommendation_model.parameters(), lr=1e-3)\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "# Function to log progress\n",
    "def log_progress(epoch, step, total_loss, log_progress_step, data_size, losses):\n",
    "    avg_loss = total_loss / log_progress_step\n",
    "    sys.stderr.write(\n",
    "        f\"\\r{epoch+1:02d}/{EPOCHS:02d} | Step: {step}/{data_size} | Avg Loss: {avg_loss:<6.9f}\"\n",
    "    )\n",
    "    sys.stderr.flush()\n",
    "    losses.append(avg_loss)\n",
    "\n",
    "total_loss = 0\n",
    "log_progress_step = 100\n",
    "losses = []\n",
    "train_dataset_size = len(train_dataset)\n",
    "print(f\"Training on {train_dataset_size} samples...\")\n",
    "\n",
    "recommendation_model.train()\n",
    "for e in range(EPOCHS):\n",
    "    step_count = 0  # Reset step count at the beginning of each epoch\n",
    "    for i, train_data in enumerate(train_loader):\n",
    "        output = recommendation_model(\n",
    "            train_data[\"users\"].to(device), train_data[\"items\"].to(device)\n",
    "        )\n",
    "        # Reshape the model output to match the target's shape\n",
    "        output = output.squeeze()  # Removes the singleton dimension\n",
    "        ratings = (\n",
    "            train_data[\"ratings\"].to(torch.float32).to(device)\n",
    "        )  # Assuming ratings is already 1D\n",
    "\n",
    "        mask = train_data[\"genre_mask\"].to(device)\n",
    "\n",
    "        loss = loss_func(output, ratings, mask.squeeze(), 0, None)\n",
    "        total_loss += loss.sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # Increment step count by the actual size of the batch\n",
    "        step_count += len(train_data[\"users\"])\n",
    "\n",
    "        # Check if it's time to log progress\n",
    "        if (\n",
    "            step_count % log_progress_step == 0 or i == len(train_loader) - 1\n",
    "        ):  # Log at the end of each epoch\n",
    "            log_progress(\n",
    "                e, step_count, total_loss, log_progress_step, train_dataset_size, losses\n",
    "            )\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0354\n",
      "RMSE per genre:\n",
      "Action         : 1.0343\n",
      "Drama          : 0.9656\n",
      "Comedy         : 1.1048\n",
      "Thriller       : 1.0040\n",
      "Children       : 1.1943\n",
      "Adventure      : 1.0414\n",
      "Musical        : 1.1092\n",
      "Romance        : 1.0462\n",
      "War            : 1.0040\n",
      "Crime          : 1.0520\n",
      "Sci-Fi         : 1.0445\n",
      "Horror         : 1.0401\n",
      "Mystery        : 0.9910\n",
      "Documentary    : 1.0013\n",
      "Western        : 1.1606\n",
      "Animation      : 1.0675\n",
      "Film-Noir      : 0.9796\n",
      "Fantasy        : 0.8469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float32(0.084586136)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "cats = []\n",
    "\n",
    "recommendation_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, valid_data in enumerate(val_loader):\n",
    "        cats.extend(valid_data[\"genre_mask\"].cpu().numpy())\n",
    "        output = recommendation_model(\n",
    "            valid_data[\"users\"].to(device), valid_data[\"items\"].to(device)\n",
    "        )\n",
    "        ratings = valid_data[\"ratings\"].to(device)\n",
    "        y_pred.extend(output.cpu().numpy())\n",
    "        y_true.extend(ratings.cpu().numpy())\n",
    "\n",
    "# Calculate RMSE\n",
    "rms = root_mean_squared_error(y_true, y_pred)\n",
    "print(f\"RMSE: {rms:.4f}\")\n",
    "\n",
    "# Get RMSE for each genre\n",
    "genre_rmses = defaultdict(list)\n",
    "for cat, pred, true in zip(cats, y_pred, y_true):\n",
    "    genre_rmses[cat.argmax()].append((pred - true) ** 2)\n",
    "\n",
    "for genre, rmses in genre_rmses.items():\n",
    "    genre_rmses[genre] = np.sqrt(np.mean(rmses))\n",
    "\n",
    "print(\"RMSE per genre:\")\n",
    "for genre, rmse in genre_rmses.items():\n",
    "    print(f\"{train_dataset._genre_lbl_enc.inverse_transform([genre])[0]:<15}: {rmse:.4f}\")\n",
    "\n",
    "# compute mean difference between genres\n",
    "diff = []\n",
    "for genre1 in genre_rmses:\n",
    "    for genre2 in genre_rmses:\n",
    "        if genre1 != genre2:\n",
    "            diff.append(abs(genre_rmses[genre1] - genre_rmses[genre2]))\n",
    "\n",
    "sum(diff) / len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision @ 50: 0.8738\n",
      "recall @ 50: 0.8639\n"
     ]
    }
   ],
   "source": [
    "def calculate_precision_recall(user_ratings, k, threshold):\n",
    "    user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "    n_rel = sum(true_r >= threshold for _, true_r in user_ratings)\n",
    "    n_rec_k = sum(est >= threshold for est, _ in user_ratings[:k])\n",
    "    n_rel_and_rec_k = sum((true_r >= threshold) and (est >= threshold) for est, true_r in user_ratings[:k])\n",
    "\n",
    "    precision = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "    recall = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "    return precision, recall\n",
    "\n",
    "user_ratings_comparison = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for valid_data in val_loader:\n",
    "        users = valid_data[\"users\"].to(device)\n",
    "        movies = valid_data[\"items\"].to(device)\n",
    "        ratings = valid_data[\"ratings\"].to(device)\n",
    "        output = recommendation_model(users, movies)\n",
    "\n",
    "        for user, pred, true in zip(users, output, ratings):\n",
    "            user_ratings_comparison[user.item()].append((pred[0].item(), true.item()))\n",
    "\n",
    "user_precisions = dict()\n",
    "user_based_recalls = dict()\n",
    "\n",
    "k = 50\n",
    "threshold = 3\n",
    "\n",
    "for user_id, user_ratings in user_ratings_comparison.items():\n",
    "    precision, recall = calculate_precision_recall(user_ratings, k, threshold)\n",
    "    user_precisions[user_id] = precision\n",
    "    user_based_recalls[user_id] = recall\n",
    "\n",
    "\n",
    "average_precision = sum(prec for prec in user_precisions.values()) / len(user_precisions)\n",
    "average_recall = sum(rec for rec in user_based_recalls.values()) / len(user_based_recalls)\n",
    "\n",
    "print(f\"precision @ {k}: {average_precision:.4f}\")\n",
    "print(f\"recall @ {k}: {average_recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

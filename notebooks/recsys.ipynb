{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import lightning as L\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class MatrixFactorization(L.LightningModule):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def forward(self, user_id, item_id):\n",
    "        user_vector = self.user_embedding(user_id)\n",
    "        item_vector = self.item_embedding(item_id)\n",
    "        return (user_vector * item_vector).sum(1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_id, item_id, rating = batch\n",
    "        prediction = self(user_id, item_id)\n",
    "        loss = nn.functional.mse_loss(prediction, rating)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.SGD(self.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, dataframe=None):\n",
    "        self.dataframe = self.load_movielens_data() if dataframe is None else dataframe\n",
    "        self.num_users = self.dataframe['user_id'].nunique()\n",
    "        self.num_items = self.dataframe['item_id'].nunique()\n",
    "\n",
    "    @staticmethod\n",
    "    def load_movielens_data(path_u='data/ml-100k/u.data'):\n",
    "        column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "        df = pd.read_csv(path_u, sep='\\t', names=column_names)\n",
    "        df['user_id'] -= 1\n",
    "        df['item_id'] -= 1\n",
    "        return df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_id = self.dataframe.iloc[idx, 0]\n",
    "        item_id = self.dataframe.iloc[idx, 1]\n",
    "        rating = self.dataframe.iloc[idx, 2]\n",
    "        return (\n",
    "            torch.tensor(user_id, dtype=torch.long),\n",
    "            torch.tensor(item_id, dtype=torch.long),\n",
    "            torch.tensor(rating, dtype=torch.float)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = MovieLensDataset.load_movielens_data()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type      | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | user_embedding | Embedding | 30.2 K | train\n",
      "1 | item_embedding | Embedding | 52.7 K | train\n",
      "-----------------------------------------------------\n",
      "82.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "82.9 K    Total params\n",
      "0.332     Total estimated model params size (MB)\n",
      "2         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Users/dominykas.seputis/github/msc-thesis/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1250/1250 [00:06<00:00, 187.37it/s, v_num=72]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1250/1250 [00:06<00:00, 187.28it/s, v_num=72]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MovieLensDataset(train_df)\n",
    "test_dataset = MovieLensDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "model = MatrixFactorization(train_dataset.num_users, train_dataset.num_items, 32)\n",
    "trainer = L.Trainer(max_epochs=10)\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8109, -4.2718, -0.9283, -1.0590, -2.5068,  4.4384,  3.7847,  0.6953,\n",
      "         1.1353,  3.0365,  4.0712, -1.5655,  8.3063, -6.2752, -3.1119,  1.8457,\n",
      "         0.0949,  0.4974, -1.5860, -2.3402,  4.1899, -0.3536,  5.8201,  1.7977,\n",
      "         0.7605,  0.9641, -4.0269, -1.7355, -0.3192,  6.5090, -2.0786,  1.2006,\n",
      "         1.8513, -0.5446, -0.0166,  2.3374,  0.3110,  1.8306,  1.2042,  0.3505,\n",
      "         3.8013,  3.6846,  0.0374,  4.1648, -0.8510, -5.0725,  0.9266, -4.5456,\n",
      "        -3.3205, -1.5469,  0.6198,  2.7928,  0.4988, -0.8167, -0.4994, -2.5567,\n",
      "         1.8124,  3.7027, -0.2175, -0.1840,  3.2345, -5.6300, -0.2207, -1.9232],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([ -0.0623,   2.9896,  -2.7594,   3.9754,   6.8108,   1.2885,  -2.7222,\n",
      "          5.3615,   1.0612,   0.8897,  -3.0274,   3.1576,  -1.3941, -12.9348,\n",
      "         -2.1775,  -2.1606,   2.9174,   0.4766,   0.9635,   0.8593,  -0.7423,\n",
      "         -2.4109,   3.0689,  -7.5407,   4.7294,   0.9155,   0.5348,   6.2378,\n",
      "          3.7361,  -0.5992,  -2.8107,  -4.2491,  -7.2763,  -1.9262,   4.9224,\n",
      "         -1.5077,  12.0696,   2.8198,  -2.1653,   2.1420,   0.2219,   0.7669,\n",
      "          2.4803,   1.2461,  -0.3988,   2.8458,  -0.8011,  -3.3929,  -0.0584,\n",
      "         -3.5125,  -2.6196,   1.3609,  -7.5195,   0.5535,  -0.4034,  -0.4309,\n",
      "         -2.3410,   7.7310,   0.5488,  -4.0761,   5.1113,  -0.5847,   2.4251,\n",
      "         -1.1147], grad_fn=<SumBackward1>)\n",
      "tensor([-1.8169,  5.8324, -1.2256, -1.6968, -3.0444,  3.1566, -0.6587,  3.3437,\n",
      "         6.4516,  4.3889, -1.0673,  0.0418, -0.4070,  0.8814, -8.7155, -1.9967,\n",
      "        -3.3809,  0.1187, -0.6888,  3.3697,  1.0379,  3.7039,  2.0154,  3.5927,\n",
      "        -2.1474, -1.1682, -2.8580, -1.1356,  8.7083, -0.7347, -1.0671, -3.2035,\n",
      "         1.0282,  2.1727,  3.3247,  1.6731,  1.5630,  1.7097, -2.9353, -0.7366,\n",
      "        -3.5413, -1.3926,  5.4911, -1.1446, -2.0216,  0.5958,  1.7277, -3.2522,\n",
      "         3.7649,  7.0841, -1.9370,  0.3803, -2.7638,  0.1241,  4.5345,  4.1515,\n",
      "         1.0401,  5.8193, -2.2179,  1.8007,  0.4451, -1.2618, -3.5465, -1.3776],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([-3.0290e-01,  9.1175e-01,  1.2226e+00, -4.6436e+00, -1.6526e+00,\n",
      "        -5.4883e-01,  2.4360e+00,  9.2489e-04, -4.0323e-01,  6.3993e+00,\n",
      "         7.3226e-01,  3.4592e+00,  7.3558e+00,  1.8534e+00, -1.6092e+00,\n",
      "        -2.9656e-02, -5.1602e+00,  2.8823e+00,  6.1105e-01,  3.3478e+00,\n",
      "         2.7511e-01,  1.4650e-01,  8.9857e-01,  4.1867e+00,  9.8771e-01,\n",
      "        -3.8880e+00,  1.6990e+00,  5.4943e+00, -1.2662e+00,  1.7000e+00,\n",
      "         1.7526e+00, -3.7562e+00,  3.6642e-02,  4.0210e+00, -1.3544e+00,\n",
      "        -3.4211e-01, -2.9846e+00, -3.1782e-02,  5.3992e+00,  5.1178e-01,\n",
      "         8.8401e-01,  1.9362e+00,  6.7301e-01, -8.9841e-01,  1.1552e+00,\n",
      "         4.2949e+00,  4.6477e+00, -4.4953e+00,  2.3606e+00, -2.6593e+00,\n",
      "        -2.1824e+00, -2.0353e-01,  6.3576e-01, -4.8812e-01,  1.0117e+00,\n",
      "        -2.0293e+00,  2.3491e+00,  3.1324e+00,  1.7381e+00,  4.9860e+00,\n",
      "         1.5687e+00, -1.2812e+00,  9.8682e-01,  1.0364e+00],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([ 3.0736,  0.4782,  3.4988, -0.1885,  3.0327,  2.7567, -0.2723, -1.1174,\n",
      "         6.0788,  0.1736,  0.6675,  2.6277,  0.2411, -5.9665,  1.9748,  2.0116,\n",
      "         5.2617, -1.2715,  1.7144, -2.1343, -0.1784,  0.7254, -3.0774,  0.6866,\n",
      "         5.6783,  5.1863,  2.4140, -3.9465, -2.0899, -2.5788, -2.7752,  1.3889,\n",
      "         4.0140,  0.0179, -3.8200,  3.5360,  0.6097,  0.4819,  0.3575,  5.4826,\n",
      "         0.5641, -1.4534,  0.9864,  1.0468, -0.2565, -3.2943, -1.3091, -2.2120,\n",
      "        -4.4628, -1.3758, -2.3332,  0.1557,  4.0464,  2.6126, -1.5015,  3.6941,\n",
      "         3.9230, -0.5698,  7.5530,  1.1992, -5.3097, -0.2969,  2.0018, -4.7569],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([-5.2379, -3.2569, -1.4144, -0.2049,  0.3182, -1.9582, -4.7829, -0.5031,\n",
      "        -1.3942, -0.7777,  1.2074,  0.0581, -0.6202,  0.7144,  0.3931, -5.4232,\n",
      "         3.1113, -1.0448, -2.0211,  2.4444,  3.9502,  7.4228,  0.0205, -5.6291,\n",
      "         6.1173, -0.4423,  4.1621, -0.5009,  1.3854, -1.5619, -4.3897,  1.6113,\n",
      "        -1.6114,  1.1357,  0.3130,  1.8941,  0.2818, -4.1323,  0.6706, -1.7816,\n",
      "        -1.4460,  1.5624, -7.4498, -0.5677,  1.3838,  1.4738, -0.1685,  4.5626,\n",
      "         3.3674, -1.9913, -0.4629,  3.4554, -1.5624,  3.8513,  3.2381,  2.2354,\n",
      "         3.8636, -1.3840,  7.1909, -1.7183, -1.4967,  6.0416,  0.3319,  0.2375],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([ 9.7088, -3.4056,  0.7671, -0.9461,  3.0872, -2.8842,  0.8887,  4.2058,\n",
      "        -6.7303, -1.4842, -3.2296, -2.5583,  0.6849,  1.2681, -2.7713, -2.7177,\n",
      "        -0.0745, -0.7099,  6.0124, -1.7662, -2.8523,  0.4504,  0.4350,  3.3886,\n",
      "         1.9113,  3.0835,  4.6602, -2.5823,  1.7181,  1.2486, -6.4862, -3.9128,\n",
      "         1.6227, -0.2098,  1.8500,  0.1360, -1.8398,  2.3309,  1.8606, -1.9724,\n",
      "        -3.2260,  2.0906,  2.4188,  0.6082,  0.9246,  0.7499,  0.7975, -8.0900,\n",
      "        -0.6541, -0.6176, -2.6265, -0.2166, -2.1912,  1.2189, -5.3104,  0.2731,\n",
      "        -3.5207,  1.2090, -5.0923,  2.7310, -3.6321,  3.1802,  6.8819,  1.9268],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([  1.1472,  -0.5254,   7.1818,   1.3137,   1.1966,   7.9611,  -2.5098,\n",
      "          3.8675,  -3.5209,   1.6978,  -1.5056,   4.9236,   0.9886,  -2.1898,\n",
      "          0.8958,   3.3115,   1.3542,  -4.2616,   2.7076,   0.0386,   0.2957,\n",
      "         -2.2476,  -0.8399,  -6.8090,   0.8918,   2.2703,  -0.1529,   6.0298,\n",
      "         -4.9015,   3.0356,  -3.2669,   2.6354,   0.1533,  -2.4818,  -2.2410,\n",
      "         -0.1077,   5.2582,  -2.7253,  -0.9522,  -2.1283,   3.2875,   0.5558,\n",
      "         -1.6123,  -2.1973,  -2.8969,   2.2641,   1.0781,  -0.4101,   1.8692,\n",
      "         -3.3804,  -1.8026,   0.8285,  -3.3052,  -5.2042,  -2.7724,  -0.2874,\n",
      "          1.1039,  -2.7700,  -5.4982,  -3.3344,   1.4934, -11.4388,   2.2622,\n",
      "          1.5880], grad_fn=<SumBackward1>)\n",
      "tensor([ 6.0291e+00, -4.8596e+00,  1.2050e+00,  1.5861e+00, -1.2900e+00,\n",
      "        -3.9534e+00, -5.0337e+00, -6.5023e-01,  4.7730e-01, -1.7576e+00,\n",
      "        -3.4952e+00,  3.8451e+00,  6.6212e+00, -8.4314e+00, -3.7990e+00,\n",
      "        -1.3294e+00, -3.0883e+00, -2.9334e+00, -1.4327e+00, -2.3176e-02,\n",
      "         1.1758e+00,  2.1613e+00,  2.6321e+00,  2.9638e+00, -1.7853e+00,\n",
      "        -8.1013e+00, -1.2418e+01,  2.1963e+00,  3.7036e+00, -1.0222e+01,\n",
      "         2.3560e-01, -6.5434e-01,  1.5033e-01, -1.6414e-01, -1.3603e+00,\n",
      "         7.7943e+00, -6.3604e+00,  8.8518e-01, -4.3999e-01, -3.9388e+00,\n",
      "         1.2157e+00,  2.3478e+00, -1.4875e+00, -1.0640e+00,  4.6642e+00,\n",
      "        -3.1370e+00, -2.9888e+00,  6.7596e-01, -5.5892e-01, -1.0696e+00,\n",
      "        -1.4002e+01, -3.5394e-02,  6.4412e-01,  2.4460e+00,  4.9392e-01,\n",
      "         4.6442e-01,  1.9297e+00, -2.2697e+00,  3.7753e+00, -5.1379e+00,\n",
      "        -1.1039e-02,  2.3861e-01,  1.2774e+00,  9.1747e-01],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([ 5.5918, -0.7754, -1.6515, -1.2126, -4.5734, -3.0491, -0.1855,  1.3293,\n",
      "        -0.8660, -4.8339, -0.7188, -0.9608,  6.0334, -1.0526,  2.7940,  6.5847,\n",
      "        -9.2528, -4.5480,  2.6836, -1.5108,  0.2927,  4.0862, -0.4911,  3.1797,\n",
      "        -0.6441,  1.8765, -0.5102, -2.7101, -0.3432, -1.7535, -1.0652,  0.7768,\n",
      "         2.4777, -1.5186,  4.7557, -0.4288,  0.6540,  3.5689, -3.1388, -0.8343,\n",
      "        -0.8699,  0.3956, -2.8404, -3.6065, -3.2350,  1.3322,  2.8885,  3.9179,\n",
      "        -6.0557,  3.3429,  2.5717,  1.9214, -0.8992,  3.9811,  6.4500, -4.4365,\n",
      "         3.5199,  3.0299, -0.0135,  0.9221, -1.1271, -6.1846,  1.9329,  0.5313],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([-3.4778, -3.0627,  1.9449,  0.9715,  0.5280, -8.9124,  3.8546, -1.0089,\n",
      "         5.0423,  1.6114,  7.6589, -3.6754, -2.9402,  2.7430,  0.3794, -3.4556,\n",
      "         3.7336,  2.2872, -1.5103, -2.5656, -2.2966, -5.8461, -2.4676, -8.6435,\n",
      "         2.3704, -1.7531,  1.1808,  4.3480,  3.6955,  4.0145, -3.1300,  1.5003,\n",
      "        -2.3174,  0.4300,  1.1654, -0.9416, -1.9717,  1.2524, -2.3240,  7.3355,\n",
      "         0.2969,  1.0574, -2.0096,  5.7815,  2.7003,  3.0653,  3.5107,  3.1349,\n",
      "         1.9188,  0.7910, -0.2956, -1.2813,  2.4417, -3.2186,  5.8908,  5.7787,\n",
      "         4.6386,  2.0097, 10.7640, -3.3895, -2.1746,  4.8159,  1.0977, -2.9928],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([ 4.0360e+00, -1.7152e-03,  8.0196e+00,  2.3267e-01,  3.7237e+00,\n",
      "         4.2790e+00,  1.4053e+00,  8.2651e+00,  6.0409e-01, -4.9549e-01,\n",
      "        -3.3123e+00, -1.6421e+00, -3.1278e-01, -4.7771e+00, -1.2323e+01,\n",
      "         1.5540e+00,  4.9188e+00, -1.1444e+00, -1.2036e+00, -3.1526e-01,\n",
      "         4.8425e+00,  7.8815e-01, -6.7912e+00, -1.9041e-01, -7.7342e-01,\n",
      "        -6.3154e+00,  3.2179e-01,  1.7442e+00,  8.7236e-01,  6.5719e+00,\n",
      "        -7.4285e-01, -3.5692e+00, -1.9446e+00,  1.3238e+00, -3.5710e+00,\n",
      "         1.9807e+00, -2.1203e+00,  5.8057e+00,  3.2149e+00,  1.1321e+00,\n",
      "        -6.6227e+00,  3.1161e+00,  2.6226e+00, -7.5096e-01, -3.4016e-01,\n",
      "        -1.3633e+00, -4.3298e+00,  2.6179e+00,  1.6202e+00, -2.2722e+00,\n",
      "        -4.4276e-01,  1.3778e+00, -5.7519e+00, -6.9300e+00,  2.3135e+00,\n",
      "        -1.8039e+00, -1.6683e-01,  2.8378e+00, -3.7676e+00, -6.3576e+00,\n",
      "        -1.9097e+00, -1.1211e-01, -1.4949e+00, -7.0212e-02],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([  0.5957,  -3.7112,  -0.9178,   1.2630,   2.4854,  -2.8854,   3.5091,\n",
      "          1.6095,   0.9250,  -4.0077,  -0.6153,   5.7694,   2.4107,   5.4366,\n",
      "         -0.2055,  -3.8625,   9.6528,   0.8210,  -0.8890,  -1.6578,   3.3845,\n",
      "          0.8140,   0.8099,  -0.5703,   4.3444,  -1.7778,   0.9361,  -0.5739,\n",
      "         -3.5909,  -1.0905,   1.0062, -10.8424,   1.1497,  -4.1014,  -4.9309,\n",
      "         -2.0612,   2.1302,   3.6086,  -4.8841,   2.3344,   4.8635,  -4.3294,\n",
      "          8.5141,  -0.5026,   2.7028,   4.4274,  -0.4789,  -1.3232,   1.0227,\n",
      "          6.0433,   0.6142,  -4.0319,  -2.2230,   0.4190,  -3.1301,   3.1597,\n",
      "         -5.6643,  -1.4907,  -6.9284,   0.2659,  -1.5845,   5.4984,  -1.6936,\n",
      "          4.5730], grad_fn=<SumBackward1>)\n",
      "tensor([-2.3836e+00, -2.7814e+00,  1.7994e+00, -3.8811e+00, -1.2725e+00,\n",
      "         6.3492e+00, -3.3668e+00,  7.1573e-01,  6.2016e-01,  3.0293e+00,\n",
      "         1.9535e+00,  2.1658e+00,  1.6125e+00,  2.0923e+00,  8.9924e-01,\n",
      "         8.7730e-01, -3.6645e+00,  1.3606e+00, -6.8059e+00,  2.2740e+00,\n",
      "         3.9620e+00,  2.1107e+00,  1.4789e+00, -2.5982e+00, -7.0094e-01,\n",
      "         4.8215e+00, -2.7807e+00,  4.6928e-01,  1.8515e+00,  1.6162e+00,\n",
      "         4.2626e+00, -6.0754e+00, -1.9024e+00,  7.5003e-01,  1.7637e+00,\n",
      "        -2.7677e+00, -2.2535e-01, -3.2500e-02,  4.7466e+00,  4.4614e-03,\n",
      "        -1.9982e+00, -3.1147e-01,  5.6363e-01,  4.1779e+00, -9.6422e-01,\n",
      "         2.4967e+00, -4.4884e+00,  9.8979e-01,  7.6727e-01, -7.4006e-01,\n",
      "         1.0221e+00,  1.7254e+00, -1.1101e+00,  1.9212e+00,  2.3951e+00,\n",
      "         1.4540e-01,  2.2565e+00, -1.1327e+00, -3.2417e-01, -2.3262e+00,\n",
      "        -4.2935e-01,  1.1351e+00,  2.0362e+00, -7.2799e+00],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([  1.5039,  -1.9992,  -3.7998,  -1.2729,   1.7127,  -5.4722,   0.0649,\n",
      "          2.7295,   5.1926,   3.7477,   2.9536,  -0.7823,   1.2552,  -3.4893,\n",
      "          3.0554,  -1.3873,   2.4825,   3.8569,   1.1181,   0.1878, -11.4132,\n",
      "         -0.0597,   2.0374,  -1.5818,  -1.6411,   2.0980,  -3.0092,   1.4558,\n",
      "         -0.6546,  -3.6984,   2.3546,  -1.0626,  -5.9086,   0.8929,   0.8366,\n",
      "         -6.3507,   4.2865,  -3.3655,   2.7061,  -0.1709,  -0.4393,   1.0194,\n",
      "          4.9421,   1.2108,  -5.0167,  -0.2324,  -2.3546,  -4.0704,   0.0460,\n",
      "          4.4472,   0.4801,  -0.5400,  -1.4114,  -3.4565,   2.7833,  -0.7008,\n",
      "         -5.5449,   3.6782,   4.0124,  -0.1929,  -0.5730,  -1.3268,   0.6901,\n",
      "          0.4097], grad_fn=<SumBackward1>)\n",
      "tensor([ 9.1811, -1.2454, -4.4612,  1.0212,  0.5535,  1.9351, -0.5517,  3.6346,\n",
      "        -1.8884,  1.2722,  2.0548, -3.5864, -0.2307,  0.1896,  1.5188, -0.4612,\n",
      "        -0.4622, -0.4470,  2.7018,  1.6329,  4.6250,  4.8447,  0.4381,  2.8373,\n",
      "        -0.3612, -4.2112, -0.0503, -1.9087, -5.3533,  2.6118,  4.8450,  4.1143,\n",
      "         3.3012,  4.2010,  0.7685, -1.8338,  0.9111,  0.2551,  3.3191, -0.8668,\n",
      "        -3.8583,  0.5033,  0.8177, -0.7560,  0.5984, -2.3108,  2.4538, -3.3258,\n",
      "        -5.9967,  5.4272, -3.4277, -0.0665,  0.7897,  4.4072, -2.9513,  6.2357,\n",
      "        -0.6195,  8.3089,  1.4269, -0.2977, -4.2687, -6.6103, -0.2519, -1.6631],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([ 3.5863,  7.7784,  0.6223, -1.9350, -0.1393,  4.4447, -2.7947,  1.3413,\n",
      "        -1.0471, -0.2940, -3.3315,  1.1282, -1.0905,  1.3452,  3.7201,  2.0805,\n",
      "         3.0031,  1.8538,  3.7174, -2.8631, -2.1558, -1.5294,  1.4515,  3.2044,\n",
      "        -0.3996, -5.0319, -0.2971,  2.9120, -2.5317, -4.6330,  2.0576,  1.0180,\n",
      "        -2.0562, -0.6713,  1.7661, -9.2303,  2.2107,  1.1388, -4.8196, -1.6518,\n",
      "        -1.2374,  8.3924,  1.8444, -0.3757, -1.6704, -4.7795,  2.9818, -1.2845,\n",
      "        -4.3290, -3.8751, -1.1815, -4.3610,  2.9463,  1.8587, -2.7968, -2.8875,\n",
      "         3.4217, -0.6680, -1.9658,  0.2821, -1.8807,  7.1354,  6.4137,  0.9750],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([-0.3465, -1.7210,  2.2602,  0.3164, -0.6929,  0.3010,  4.6346,  5.5821,\n",
      "         1.7801, -1.3390,  2.3549,  5.2321,  6.5275, -0.0396,  4.3719,  7.7379,\n",
      "         1.1295,  3.5693,  0.1335, -0.4184, -6.6202, -1.1735,  3.5453,  2.0536,\n",
      "        -1.0755, -1.0716, -4.0818, -3.3148, -7.2698, -4.9364, -2.0616,  3.4270,\n",
      "         1.4712, -1.7499,  0.2890,  1.5781, -6.2990,  0.1292,  1.6670, -0.7330,\n",
      "        -0.9469, -0.3662,  3.8156,  2.2336,  3.8410, -0.9956, -2.1781,  1.6791,\n",
      "        -1.1682, -7.0496,  5.7936, -0.8947,  0.0482,  0.2089,  4.0350,  1.9242,\n",
      "         5.6632,  0.8481, -1.2032,  0.8829,  0.0312,  3.5978, -1.3960, -3.8340],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([ -1.7705,   0.2705,   1.4680,  -2.5184,   2.2011,   0.3118,  -4.2607,\n",
      "          2.1215,   3.0070,   1.6609,   0.9168,  -3.4405,   3.0291,   0.8089,\n",
      "         -4.3372,  -0.1693,   0.2046,   0.6607,   0.9069,   2.2854,   2.0890,\n",
      "          3.0173,  -0.7065,  -0.7783,   3.2818,  -6.1636,   2.0761,   2.8356,\n",
      "         -2.2106,   0.9470, -10.1593,   9.9194,   1.1242,  -3.3019,   3.7207,\n",
      "          3.3937,   1.8031,   2.4715,   1.3707,   6.1733,   2.4933,  -7.9456,\n",
      "         -7.3869,   5.3027,  -3.8048,   0.3004,  -1.1700,  -3.3392,  -0.1552,\n",
      "         -0.5261,   2.9220,  -0.7581,  -0.2516,   3.1354,   0.7742,   0.7801,\n",
      "         -1.2801,   1.3613,  -1.0016,   0.6577,  -0.1141,  -3.1706,  -3.8234,\n",
      "          0.4885], grad_fn=<SumBackward1>)\n",
      "tensor([ -3.5671,  -1.1841,   0.8798,  -0.7040,  -1.0721,   5.8993,  -3.3419,\n",
      "          2.0294,   0.4218,   6.5765,   3.1209,  -0.1162, -11.0567,  -2.4636,\n",
      "         -1.9033,   3.4101,  -2.1162,  -2.3939,  -2.6325,  -1.0136,   0.3182,\n",
      "         -1.1683,   6.2733,   4.2709,  -4.2078,   8.6749,  -1.5279,  10.3269,\n",
      "          1.0688,  -4.3644,   2.5874,   4.6604,   3.3903,   0.3060,  -3.2392,\n",
      "         -1.7962,  -4.7341,  -3.3711,  -6.8187,   1.0467,   0.6006,  -4.7625,\n",
      "         -2.0972,  -0.1020,   1.7834,   2.2793,   3.4342,   0.0565,   3.0040,\n",
      "         -3.1841,  -5.1370,  -2.0574,   0.0955,  -0.9327,   2.4960,   3.7474,\n",
      "         -1.1725,  -0.5743,  -3.1945,   1.3792,  -1.4494,   0.0689,   1.0723,\n",
      "         -3.0579], grad_fn=<SumBackward1>)\n",
      "tensor([-0.2372,  2.9025,  2.3418,  1.6017,  1.5495, -3.6220, -4.8406,  4.1256,\n",
      "         1.9787,  0.1995,  3.2138, -2.4914,  2.6003, -5.6863, -0.9083,  0.5030,\n",
      "        -0.7101,  0.4038,  0.5711, -0.8666, -2.8719,  2.6167, -4.2820,  1.2546,\n",
      "         0.4660,  1.4393, -5.3671, -1.3960,  1.0648, -0.7469,  3.9035,  2.7359,\n",
      "        -0.9285, -5.8050,  3.0384,  3.3102,  0.0608,  2.6238,  3.3910,  0.5184,\n",
      "        -4.4059,  4.4071, -1.2141,  0.5046,  1.8599,  8.0604, -3.0428,  4.1137,\n",
      "        -1.3947, -7.0104, -0.7014,  0.8849, -2.0726,  3.0821, -2.4193, -1.2147,\n",
      "        -3.7534, -2.6084, -0.5365, -0.3751, -4.3047, -2.5122,  2.0935,  0.4078],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([ 1.6624e+00, -8.9867e-01, -7.6892e-01, -2.1071e+00, -2.8262e+00,\n",
      "        -2.3741e+00,  1.7011e+00,  4.4301e-01,  5.1128e+00, -6.2934e+00,\n",
      "        -2.0810e+00, -1.1019e+00,  1.1693e+00, -7.2591e-01, -6.8360e+00,\n",
      "         2.0887e+00, -6.6069e+00,  1.6439e+00, -4.5520e+00, -1.1570e-01,\n",
      "         4.4003e+00, -6.2850e-01,  4.0702e-01,  2.2530e-01,  1.0491e+00,\n",
      "        -5.8829e+00,  1.1856e+00, -1.0400e+01,  1.6897e+00, -3.3135e+00,\n",
      "        -2.3889e+00,  6.2970e+00,  4.4856e-01, -9.8204e-01,  4.6046e+00,\n",
      "        -5.2739e-02,  6.0882e+00, -1.8921e+00,  7.1326e-01, -1.3595e+00,\n",
      "        -3.6737e+00,  9.0420e-04,  4.6475e+00,  8.2373e+00,  7.1497e-01,\n",
      "        -3.0643e+00,  1.2421e+00,  1.5636e+00,  2.3030e+00,  1.9706e+00,\n",
      "         8.9468e-01,  2.1097e+00,  1.3208e-01,  1.8288e+00,  2.9684e+00,\n",
      "        -1.6565e+00, -6.1095e-01, -3.0608e+00, -2.4831e+00, -1.2787e+00,\n",
      "         3.4229e+00, -5.2939e+00, -5.0692e+00,  2.0426e+00],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([ -0.6937,  -0.5110,   3.1217,   2.2562,   0.2141,   4.2383,  -2.1034,\n",
      "          1.2763,  -7.0008,  -1.4241,   0.3856,  -0.1798,   0.9942,   0.4528,\n",
      "          2.9147,   6.0051,   0.8368,   2.6414,  -0.8962,   0.7261, -10.4029,\n",
      "         -2.7310,  -5.4417,  -1.1080,  -3.8471,  -2.1246,  -3.3601,  -1.6940,\n",
      "          0.9982,   6.0056,  -5.4996,   1.2908,  -2.1985,  -3.3300,   0.0139,\n",
      "          4.3830,  -8.3079,   2.4336,   5.3524,  -2.8821,   0.6754,   1.4339,\n",
      "          0.7338,   0.2412,  -0.7228,  -3.8044,  -4.3307,  -0.8051,  -0.0162,\n",
      "          3.8993,  -1.2429,   4.4032,  -1.0808,  -5.9351,  -4.3186,  -5.2690,\n",
      "          1.9592,   0.6633,  -2.3372,   3.2627,   0.5029,   1.8022,   4.8508,\n",
      "         -1.7269], grad_fn=<SumBackward1>)\n",
      "tensor([-1.7220,  2.7096,  1.3994,  1.0172,  3.4015,  0.0945, -2.5686,  2.6425,\n",
      "        -3.3128,  2.4125,  3.8842, -2.7841,  1.0715,  1.4253,  3.1881, -0.0407,\n",
      "         0.5602, -1.2787, -1.1753, -0.7127,  1.2661,  1.3920, -3.0470, -1.1828,\n",
      "        -1.1880, -2.0176,  0.0127,  4.8001,  2.6810,  0.5126, -0.1117,  1.7486,\n",
      "        -1.3950, -4.1021,  1.3448,  0.9586, -3.1015,  1.3118,  0.9005,  5.4133,\n",
      "        -1.4928,  1.4204, -4.6829,  1.7241, -1.6111, -4.9900, -1.1396,  0.6524,\n",
      "        -3.3928, -2.0819,  7.9237,  2.6279,  3.1503,  1.0761, -2.5402,  5.0159,\n",
      "        -2.2912,  6.1473, -1.4226, -4.1387, -1.1957, -2.7379,  1.4254,  1.0466],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([ 1.0538, -5.9428,  1.5757,  3.1503,  3.3102,  5.1744,  1.5301, -2.1470,\n",
      "         0.3851,  4.3462,  1.5039,  3.8563,  3.8532, -0.3554,  1.9556,  1.3018,\n",
      "         0.6171,  2.1149, -6.0052, -0.1217,  0.4473,  3.9346, -0.9337,  1.1879,\n",
      "         6.6477, -1.8510, -0.8451,  1.6028,  5.1231,  7.4074, -5.2248,  0.8895,\n",
      "        -4.6913, -1.3144, -2.7920,  2.6991, -3.3133, -1.2054,  0.6955,  1.2746,\n",
      "        -2.4802,  0.2979,  5.2803, -2.9704,  4.4830,  1.9831, -3.6411,  7.7108,\n",
      "        -1.8600, -0.3201,  1.7177, -2.2576, -2.0013, -2.9186, -1.9083,  1.9865,\n",
      "         6.3613, -0.3047, -3.2071, -0.0303, -0.0896, -2.0771,  4.7466, -0.7239],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([ 0.9191, -3.7250,  1.2865,  3.8508,  1.2933, -0.9726, -1.9990,  1.9290,\n",
      "         0.7951, -1.6083,  1.5991,  7.7329, -0.1652,  2.6002,  5.7611,  3.3725,\n",
      "        -1.0966, -4.1218, -2.0514,  2.7985,  1.3365,  0.8962, -0.1129,  0.2026,\n",
      "         2.6557, -5.1187, -1.8368, -2.4887,  2.9012, -2.2132,  3.9271,  2.6605,\n",
      "         1.5249,  1.1640, -3.5557,  1.1632,  2.8824, -6.9396,  2.4057, -1.8543,\n",
      "        -1.4237, -3.7537, -5.1729,  1.5271,  2.7814, -7.8742,  0.5031,  4.0271,\n",
      "        -1.9516,  3.4134, -3.9053,  2.6170,  0.0884,  0.1908, -8.8208,  1.2186,\n",
      "         0.5429, -8.4602, -0.9593, -1.7657,  1.5686,  1.5728,  0.2376,  0.0224],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([ 2.3968, -3.0412,  1.9553, -6.2993,  3.6940, -2.3251, -1.2803,  0.2305,\n",
      "         7.1356, -1.6164,  4.4307,  2.5765, -0.6683, -5.5861,  0.9600, -2.6231,\n",
      "        -1.5532, -0.2160,  1.0830, -0.3202, -4.2392, -8.6433, -1.6466,  0.1553,\n",
      "         5.2922,  1.6093,  5.8877,  2.9230,  4.1820,  2.9153,  0.6646,  1.4583,\n",
      "        -0.3595, -0.3099,  1.9977,  1.0952, -1.5776,  1.2486, -1.3583, -2.2418,\n",
      "        -0.3181,  1.3617,  0.0322, -0.3063, -1.7138,  4.0794, -0.9966, -3.1756,\n",
      "         3.7569, -3.2956,  0.4481,  0.7818, -0.1486, 10.8738, -1.9172, -6.0482,\n",
      "         2.8281,  1.9901,  2.2153, -4.9106, -1.2548, -1.2444,  1.0521,  0.7290],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([ 0.7616, -3.8188,  5.7458, -1.8878, -3.1040,  0.8869,  1.2183, -5.3219,\n",
      "         1.2401, -5.3511,  2.1431, -1.3192, -1.5634,  1.5153,  0.3822,  4.6226,\n",
      "         2.1538,  2.3159,  1.1207, -2.2142, -1.4011,  2.4060, -2.7763, -0.5138,\n",
      "        -2.8162,  2.9785, -4.7736, 10.5462, -6.0573, -1.2367,  1.1988,  0.7375,\n",
      "         0.5206, -1.0443, -0.2078, -1.6815, -0.6705, -1.8441, -3.2326, -2.0112,\n",
      "         1.2249, -1.5277, -1.4196,  6.5357, -1.8207,  0.7058,  0.9540, -0.0206,\n",
      "         3.5854,  0.3362,  6.5820,  2.6563, -0.6814,  5.9893,  1.8345, -3.9450,\n",
      "         1.1329, -0.3156,  4.0961,  0.8153,  2.2052, -1.5103, -2.2434,  3.5500],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([-1.1671,  0.7208,  4.1387,  3.0728,  0.8151,  0.5105,  7.5175, -1.0831,\n",
      "        -2.5707, -1.7097,  0.3465, -1.2669,  3.1501,  1.5109,  1.4960, 10.2676,\n",
      "         0.3097,  2.0824, -1.8295, -5.2404,  1.7858,  2.3120, -1.1059, -2.2323,\n",
      "         0.9068,  2.1636,  1.7344,  1.0753,  1.9501, -0.1298, -8.5267,  1.4319,\n",
      "         3.9535, -4.3464, -0.4381, -0.4001,  3.6967,  0.4366, -0.5971,  1.2427,\n",
      "        -3.6694,  2.8412, -2.5805, -4.7912, -2.3565, -6.9577,  0.0210,  1.0251,\n",
      "        -0.8150,  2.6044,  4.8263, -0.3240, -1.1632,  1.5061, -2.4300,  5.0139,\n",
      "        -4.2571, -3.6737, -1.4924,  0.4973, -4.5027,  0.8131, -1.7044,  3.2388],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([-1.3887, -2.3293, -1.6978, -0.2097,  2.5717,  7.7042,  1.1689, -6.1615,\n",
      "         2.4657,  0.7982, -6.3469,  0.8442, -1.4371,  3.8697,  3.1489,  5.3656,\n",
      "         3.5904, -1.1660,  1.0148, -1.0220,  0.3287,  0.0592, -6.3832, -0.5290,\n",
      "        -0.2155, -3.5071,  1.4837, -0.8362, -1.0873,  3.0658,  0.9187,  3.0180,\n",
      "         1.5031, -1.7079,  0.1538, -0.0813,  3.8523, -4.3484,  3.6886, -4.7095,\n",
      "        -1.6531, -3.7503, -1.1962,  4.2349, -0.4627,  2.1786,  2.5351, -1.7217,\n",
      "         3.9895,  3.2198, -3.2468,  1.8812, -1.8737,  0.2845,  2.1376, -0.5797,\n",
      "        -6.3458,  1.6701, -0.3393,  0.5624, -2.5381, -6.5323,  3.1374,  3.7543],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([ -2.3759,  -4.9470,   1.2501,  -0.6081,  10.6306,  -5.8686,   7.4766,\n",
      "         -1.1777,  -1.9720,  -0.2077,  -1.4377,   2.9427,  -2.2602,  -4.4667,\n",
      "          0.8634,   4.5536,   2.8851,   1.8803,  -1.2451,   0.7883,   3.9535,\n",
      "          0.4003,   2.8129,  -1.6305,   3.5575,  -0.6172,  -1.2423,  -1.6262,\n",
      "        -10.9625,  -8.8092,  -3.7220,   2.9565,  -6.4407,  11.7902,  -0.4361,\n",
      "          3.4204,   8.3166,   0.0850,   2.5943,  -0.1879,  -1.3907,  -4.1558,\n",
      "         -4.1644,  -4.8273,  -1.0686,  -2.8175,   2.6604,   0.2235,  -2.7819,\n",
      "          1.7113,  -0.2326,   0.7791,  -0.4828,  -3.2922,  -1.2463,   3.4664,\n",
      "          1.6430,  -3.2889,  -8.0585,   0.7874,  -1.9017,   3.5416,  -3.0091,\n",
      "          0.2146], grad_fn=<SumBackward1>)\n",
      "tensor([ 3.8276,  1.3178, -3.1446,  1.9761, -3.7968, -5.0822,  6.2787,  0.6143,\n",
      "        -5.5873,  1.7820,  3.5346,  1.2676, -1.1576,  1.4388,  3.9204, -1.5430,\n",
      "        -4.7710, -2.8409, -1.0660, -0.0333,  0.7795, -3.6794,  1.3703, -0.8343,\n",
      "        -3.0564, -1.5148,  1.0656, -5.0419,  1.7606,  5.9976,  0.2866,  2.6670,\n",
      "         1.6473,  4.1471, -1.4473,  1.2196, -2.5524,  0.6838, -1.5846, -1.1887,\n",
      "         4.3408,  2.5108, -1.3576,  2.4229,  5.0415,  7.3135, -1.3558, -8.4866,\n",
      "        -2.4334,  1.7444, -0.6256,  4.5952, -2.2242,  7.2879,  2.6083,  5.7123,\n",
      "         2.0168,  0.1232, -0.3636,  0.4743, -5.2560, -1.9611, -0.7848, -1.7240],\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([ 11.2020, -10.4898,   0.7448,  -2.1828,  -0.3923,   0.8163,  -0.1096,\n",
      "          1.3022,  -3.6893,  -0.8373,   1.2781,   0.7310,   0.3884,   0.7206,\n",
      "          6.8932,  -2.1570,   3.3239,  -5.4475,  -1.0168,   0.7437,   4.0118,\n",
      "          5.5444,  -1.4097,  -0.1026,   2.4897,   1.3232,   4.3715,  -1.7111,\n",
      "          0.7315,  -2.8880,  -1.7710,   3.8572,  -3.3302,   3.4141,   1.2512,\n",
      "          0.2411,   2.0974,  -0.3582,   3.9558,  -3.6004,   2.0989,  -0.3532,\n",
      "          1.0520,   2.3698,  -1.4379,   0.7244,   2.5778,   3.6171,  -1.3950,\n",
      "          1.9419,  -0.0364,   1.8899,  -1.7602,   0.1598,   2.0327,  -3.5595,\n",
      "         -2.3699,   0.9771,   0.7457,   4.7312,   1.2918,  -2.9524,  -0.7292,\n",
      "          3.2675], grad_fn=<SumBackward1>)\n",
      "tensor([  1.2888,   0.1814,   3.0804,   0.6787,   6.0571, -10.6583,   5.6033,\n",
      "         -1.0205,   3.3701,  -1.0723,   0.8520,   0.8006,  -1.2797,   2.0335,\n",
      "         -0.9400,  -6.4228,   1.3508,  -0.3260,  -0.3482,   5.7834,   0.3412,\n",
      "          1.0346,   1.5191,   4.0302,   2.2692,  -3.6487,   2.8645,   3.6296,\n",
      "          2.0740,  -3.6494,  -2.7588,  -6.1553,  -0.6862,   3.6443,   1.2839,\n",
      "         -1.9625,   4.9848,  -0.1694,   4.9320,  -0.6346,  -0.7792,   3.8683,\n",
      "         -1.0949,   1.0045,  -2.8542,  -2.2805,  -2.4862,   4.9849,  -1.6188,\n",
      "         -1.1391,  -0.7344,  -5.2845,   0.4820,  -5.0727,   2.2924,  -1.4073,\n",
      "          1.9319,   4.3238,   0.6195,  -4.0076,   4.5571,  -0.3377,  -2.9768,\n",
      "          3.7372], grad_fn=<SumBackward1>)\n",
      "tensor([ 3.2428,  0.0524, -4.7596, -1.8808,  1.4340, -0.5191, 10.2905, -0.1468,\n",
      "        -5.1988, -0.0359,  0.9388,  2.3536, -0.3230, -3.0891,  2.3565,  1.7062,\n",
      "         0.8744, -4.0883,  1.2285, -1.7160,  1.0257,  0.4493, -9.1600, -4.3570,\n",
      "         5.9584,  1.7092,  1.4275, -2.3379, -0.0498,  9.2520,  3.3769, -1.1107,\n",
      "         4.0696, -1.5483, -2.2010, -3.4483, -0.3725,  2.9547,  3.7909,  6.6475,\n",
      "         1.1877,  0.3528, -1.6088,  1.1820,  1.2216,  2.3471,  3.1328, -1.6489,\n",
      "         1.2935, -0.2819,  1.2734, -3.1710,  1.1865, -2.1126, -1.7151, -0.5374,\n",
      "        -1.0586,  1.3371,  1.6724, -3.7273,  4.0533, -0.4781, -0.3103, -3.0823],\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m      3\u001b[0m     user_id, item_id, rating \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m----> 4\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(prediction)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(prediction)\n",
      "File \u001b[0;32m~/github/msc-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/msc-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[16], line 18\u001b[0m, in \u001b[0;36mMatrixFactorization.forward\u001b[0;34m(self, user_id, item_id)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, user_id, item_id):\n\u001b[1;32m     17\u001b[0m     user_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_embedding(user_id)\n\u001b[0;32m---> 18\u001b[0m     item_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (user_vector \u001b[38;5;241m*\u001b[39m item_vector)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/github/msc-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/msc-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/github/msc-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/msc-thesis/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for batch in test_loader:\n",
    "    user_id, item_id, rating = batch\n",
    "    prediction = model(user_id, item_id)\n",
    "    predictions.append(prediction)\n",
    "    print(prediction)\n",
    "\n",
    "predictions[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

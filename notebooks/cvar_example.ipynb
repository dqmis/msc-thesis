{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df914d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy cvxpy tqdm matplotlib seaborn mosek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd1283a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dseputis1/github/msc-thesis/.venv/lib/python3.12/site-packages/sdpap/sdpap.py:2: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Apr 14 09:18:34 PM: Encountered unexpected exception importing solver GLOP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.12.4544). Expected < 9.10.0. Please open a feature request on cvxpy to enable support for this version.')\n",
      "(CVXPY) Apr 14 09:18:34 PM: Encountered unexpected exception importing solver PDLP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.12.4544). Expected < 9.10.0. Please open a feature request on cvxpy to enable support for this version.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import cvxpy as cp\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91344d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eda4ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from dropbox\n",
    "resp = requests.get(\"https://www.dropbox.com/scl/fi/05woj2mttjwzl64q29x5u/amazon_predictions.npy?rlkey=mnxzgbos28wr9t47i7ezgayow&st=kghbwpn3&dl=1\")\n",
    "with open(\"amazon_predictions.npy\", \"wb\") as f:\n",
    "    f.write(resp.content)\n",
    "\n",
    "resp = requests.get(\"https://www.dropbox.com/scl/fi/fyiu6dwf4b5959tjsp8jw/amazon_user_groups.json?rlkey=8irakhur6nf4kieex0se9vsgh&st=0mlarlkb&dl=1\")\n",
    "with open(\"amazon_user_groups.json\", \"wb\") as f:\n",
    "    f.write(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a956fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"amazon_predictions.npy\", \"rb\") as f:\n",
    "    REL_MATRIX = np.load(f)\n",
    "\n",
    "with open(\"amazon_user_groups.json\", \"r\") as f:\n",
    "    GROUPS_MAP = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha parameter used within cvar\n",
    "ALPHA = 0.7\n",
    "# for which gamma values to run the experiment (consumer-producer trade-off)\n",
    "GAMMA_POINTS = [0, 0.35, 0.7, 1]\n",
    "# select for which groups to run the experiment\n",
    "GROUPS = [\"usage_group\"]\n",
    "# GROUPS = [\"top_category\", \"usage_group\"]\n",
    "\n",
    "# number of runs\n",
    "N_RUNS = 3\n",
    "# number of consumers\n",
    "N_CONSUMERS = 300\n",
    "# number of producers\n",
    "N_PRODUCERS = 100\n",
    "# number of items to be recommended\n",
    "K_REC = 10\n",
    "\n",
    "# do not modify these values as they are used for extracting correct attributes from solution\n",
    "WEIGHTS_IDX = 1\n",
    "RHO_IDX = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac3a5c",
   "metadata": {},
   "source": [
    "Switch solvers between SCIP or MOSEK. MOSEK is more powerful. but requires license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a85d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLVER = cp.MOSEK\n",
    "SOLVER = cp.SCIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c97e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_utility(m, n, sample_m, sample_n, W):\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    users = rng.choice(m, size=sample_m, replace=False)\n",
    "    items = rng.choice(n, size=sample_n, replace=False)\n",
    "    return W[users][:, items]\n",
    "\n",
    "\n",
    "def sample_candidate_items(rel_matrix_users: np.ndarray, n_candidates: int) -> np.ndarray:\n",
    "    top_items = np.argsort(rel_matrix_users, axis=1)[:, -n_candidates:]\n",
    "    unique_items = np.unique(top_items)\n",
    "    return rel_matrix_users[np.arange(rel_matrix_users.shape[0])[:, None], unique_items]\n",
    "\n",
    "\n",
    "def _parse_groups_ids(consumer_ids, groups_map: list[dict[str, int]], group_key: str):\n",
    "    \"\"\"Parses given group key value to int for each consumer\"\"\"\n",
    "\n",
    "    consumer_groups = [i[group_key] for i in groups_map if i[\"user_id\"] in consumer_ids]\n",
    "    all_groups = list(set(consumer_groups))\n",
    "\n",
    "    return np.array([all_groups.index(i) for i in consumer_groups])\n",
    "\n",
    "def sample_users_from_groups(\n",
    "    users_count: int,\n",
    "    items_count: int,\n",
    "    groups_map: list[dict],  # assumed list of dicts, each with group_key and \"user_id\"\n",
    "    group_key: str,\n",
    "    data: np.ndarray,\n",
    "    naive_sampling: bool = True,\n",
    ") -> tuple[np.ndarray, list[int], list[int]]:\n",
    "    # Count how many times each group appears.\n",
    "    group_freq = Counter(row[group_key] for row in groups_map)\n",
    "\n",
    "    # Calculate initial allocation using proportions.\n",
    "    # (Total items in groups_map is used as denominator to reflect each group's share.)\n",
    "    initial_allocation = {\n",
    "        group: max(round(users_count * count / len(groups_map)), 1)\n",
    "        for group, count in group_freq.items()\n",
    "    }\n",
    "\n",
    "    # Adjust allocation so that sum equals exactly users_count.\n",
    "    allocated_total = sum(initial_allocation.values())\n",
    "    # Identify the \"biggest\" group (with the most occurrences)\n",
    "    biggest_group = max(group_freq.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "    if allocated_total > users_count:\n",
    "        # Too many allocated; remove the difference from the largest group, but keep at least one user.\n",
    "        diff = allocated_total - users_count\n",
    "        initial_allocation[biggest_group] = max(initial_allocation[biggest_group] - diff, 1)\n",
    "    elif allocated_total < users_count:\n",
    "        # Too few allocated; add the shortfall to the largest group.\n",
    "        diff = users_count - allocated_total\n",
    "        initial_allocation[biggest_group] += diff\n",
    "\n",
    "    # Build a mapping from group key to all available user IDs.\n",
    "    group_users = defaultdict(list)\n",
    "    for row in groups_map:\n",
    "        group_users[row[group_key]].append(row[\"user_id\"])\n",
    "\n",
    "    # Sample users from each group according to the final allocation.\n",
    "    sampled_users = []\n",
    "    for group, users in group_users.items():\n",
    "        sampled_users.extend(\n",
    "            np.random.choice(users, initial_allocation[group], replace=False)\n",
    "        )\n",
    "\n",
    "    # Use your helper to parse the groups of the sampled users.\n",
    "    group_assignments = _parse_groups_ids(sampled_users, groups_map, group_key)\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "    if naive_sampling:\n",
    "        # Sample random item indices.\n",
    "        items = rng.choice(data.shape[1], size=items_count, replace=False)\n",
    "        return data[sampled_users][:, items], sampled_users, group_assignments\n",
    "\n",
    "    rel_matrix_sampled = data[sampled_users]\n",
    "    top_items = sample_candidate_items(rel_matrix_sampled, items_count)\n",
    "    return top_items, sampled_users, group_assignments\n",
    "\n",
    "\n",
    "def compute_producer_optimal_solution(rel_matrix: np.ndarray, k_rec: int) -> cp.Problem:\n",
    "    x_alloc = cp.Variable(rel_matrix.shape, boolean=True)\n",
    "\n",
    "    # constraints\n",
    "    constraints = [\n",
    "        # recommend k items\n",
    "        cp.sum(x_alloc, axis=1) == k_rec,\n",
    "    ]\n",
    "\n",
    "    # maximize the minimal item utility\n",
    "    problem = cp.Problem(\n",
    "        cp.Maximize(cp.min(cp.sum(x_alloc, axis=0))),\n",
    "        constraints,\n",
    "    )\n",
    "    problem.solve(solver=SOLVER)\n",
    "\n",
    "    return problem\n",
    "\n",
    "def compute_consumer_optimal_solution(\n",
    "    rel_matrix: np.ndarray,\n",
    "    group_assignments: np.ndarray,\n",
    "    k_rec: int,\n",
    "    gamma: float,\n",
    "    producer_max_min_utility,\n",
    "    alpha: float = 0.95\n",
    ") -> cp.Problem:\n",
    "    # producer allocations\n",
    "    x_alloc = cp.Variable(rel_matrix.shape, boolean=True)\n",
    "\n",
    "    constraints = [\n",
    "        # there should be k_rec producers allocated to consumer\n",
    "        cp.sum(x_alloc, axis=1) == k_rec,\n",
    "        # each producer should get at least gamma * optimal producer utility\n",
    "        cp.sum(x_alloc, axis=0) >= gamma * producer_max_min_utility,\n",
    "    ]\n",
    "\n",
    "    # greedy producer allocations for consumer\n",
    "    greedy_allocations = np.sort(rel_matrix, axis=1)[:, -k_rec:].sum(axis=1)\n",
    "\n",
    "    # precomputing values for later processing\n",
    "    unique_groups, group_indices = np.unique(group_assignments, return_inverse=True)\n",
    "    num_groups = len(unique_groups)\n",
    "    group_masks = [group_indices == i for i in range(num_groups)]\n",
    "    group_sizes = np.array([mask.sum() for mask in group_masks])\n",
    "\n",
    "\n",
    "    allocations = cp.sum(cp.multiply(rel_matrix, x_alloc), axis=1)\n",
    "    # Compute normalized losses for all groups simultaneously (vectorized)\n",
    "    normalized_losses = []\n",
    "    for mask, size in zip(group_masks, group_sizes):\n",
    "        group_alloc = allocations[mask]\n",
    "        greedy_group_alloc = greedy_allocations[mask]\n",
    "\n",
    "        # compute loss for each group\n",
    "        normalized_loss = cp.sum(1 - (group_alloc / greedy_group_alloc)) / size\n",
    "        normalized_losses.append(normalized_loss)\n",
    "\n",
    "    # CVaR computation (vectorized)\n",
    "    rho = cp.Variable(nonneg=True)\n",
    "    cvar_objective = rho + (1 / ((1 - alpha) * num_groups)) * cp.sum(cp.pos(cp.hstack(normalized_losses) - rho))\n",
    "\n",
    "    # Define and solve the optimization problem\n",
    "    problem = cp.Problem(cp.Minimize(cvar_objective), constraints)\n",
    "    problem.solve(solver=SOLVER)\n",
    "\n",
    "    return problem\n",
    "\n",
    "\n",
    "def compute_consumer_producer_utils_per_gamma(\n",
    "    rel_matrix: np.ndarray, k_rec: int, gamma_points: list[float], group_assignments: list[int], alpha: float\n",
    ") -> tuple[list[list[float]], list[list[float]]]:\n",
    "    producer_max_min_utility = compute_producer_optimal_solution(rel_matrix, k_rec).value\n",
    "    greedy_allocations_per_consumer = np.sort(rel_matrix, axis=1)[:, -k_rec:].sum(axis=1)\n",
    "\n",
    "    consumers_utils = []\n",
    "    producers_utils = []\n",
    "\n",
    "    for gamma in gamma_points:\n",
    "        print(\"Computing alloactions for gamma:\", gamma)\n",
    "        v_user_result = compute_consumer_optimal_solution(\n",
    "            rel_matrix,\n",
    "            group_assignments,\n",
    "            k_rec,\n",
    "            gamma,\n",
    "            producer_max_min_utility,\n",
    "            alpha=alpha,\n",
    "\n",
    "        )\n",
    "        producer_assignments = v_user_result.variables()[WEIGHTS_IDX].value\n",
    "        consumers_utils.append(\n",
    "            (rel_matrix * producer_assignments).sum(axis=1) / greedy_allocations_per_consumer\n",
    "        )\n",
    "        producers_utils.append(producer_assignments.sum(axis=0))\n",
    "\n",
    "    return consumers_utils, producers_utils\n",
    "\n",
    "\n",
    "def compute_consumer_producer_utils_per_gamma_for_groups(\n",
    "    rel_matrix: np.ndarray,\n",
    "    n_consumers: int,\n",
    "    n_producers: int,\n",
    "    k_rec: int,\n",
    "    n_runs: int,\n",
    "    gamma_points: list[float],\n",
    "    groups_map: list[dict[str, int]],\n",
    "    group_key: str,\n",
    "    alpha: float,\n",
    "    naive_sampling: bool = True,\n",
    ") -> tuple[np.ndarray, list[int], list[float]]:\n",
    "    consumers_ids = []\n",
    "    consumers_utils = []\n",
    "    for _ in tqdm(range(n_runs)):\n",
    "        rel_matrix_sampled, consumer_ids_sampled, group_assignments = sample_users_from_groups(\n",
    "            n_consumers, n_producers, groups_map, group_key, rel_matrix, naive_sampling\n",
    "        )\n",
    "        consumer_utils_run, _ = compute_consumer_producer_utils_per_gamma(rel_matrix_sampled, k_rec, gamma_points, group_assignments, alpha)\n",
    "\n",
    "        consumers_ids.append(consumer_ids_sampled)\n",
    "        consumers_utils.append(consumer_utils_run)\n",
    "\n",
    "    return consumers_ids, consumers_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ed0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results(\n",
    "    consumers_ids: list[list[int]],\n",
    "    consumers_utils: list[list[int]],\n",
    "    n_runs: int,\n",
    "    gamma_points: list[float],\n",
    "    group_key: str\n",
    "):\n",
    "    distinct_groups = {row[group_key] for row in GROUPS_MAP if row[\"user_id\"] in consumers_ids[0]}\n",
    "    results = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for group in distinct_groups:\n",
    "        for gamma_id, gamma in enumerate(gamma_points):\n",
    "            for run_id in range(n_runs):\n",
    "                run_consumers_ids = consumers_ids[run_id]\n",
    "                run_consumer_groups = np.array([i[group_key] for i in GROUPS_MAP if i[\"user_id\"] in run_consumers_ids])\n",
    "                run_consumer_groups_idx = np.where(run_consumer_groups == group)[0]\n",
    "                run_consumers_utils = consumers_utils[run_id]\n",
    "                results[group][gamma].append(run_consumers_utils[gamma_id][run_consumer_groups_idx].mean())\n",
    "\n",
    "    consumer_utils_mean = np.mean(consumers_utils, axis=2).mean(axis=0)\n",
    "\n",
    "    return results, consumer_utils_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b983f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_groups_results(results: dict, consumer_utils_mean: np.ndarray, groups_key, group_names, save_path: str) -> None:\n",
    "    plt.figure(figsize=(10,6), dpi=300)\n",
    "    sns.set_palette(sns.color_palette(\"husl\", len(group_names)))\n",
    "    # sort results by group name\n",
    "    for group in results.items():\n",
    "        group_name, _gammas = group\n",
    "        gamma_means = {}\n",
    "        gamma_std_err = {}\n",
    "        for gamma, runs in _gammas.items():\n",
    "            gamma_means[gamma] = np.mean(runs)\n",
    "            gamma_std_err[gamma] = np.std(runs) / np.sqrt(N_RUNS)\n",
    "\n",
    "\n",
    "        plt.plot(\n",
    "            list(gamma_means.keys()),\n",
    "            list(gamma_means.values()),\n",
    "            label=f\"{group_name.capitalize()}\",\n",
    "        )\n",
    "        plt.fill_between(\n",
    "            list(gamma_std_err.keys()),\n",
    "            np.array(list(gamma_means.values())) - np.array(list(gamma_std_err.values())),\n",
    "            np.array(list(gamma_means.values())) + np.array(list(gamma_std_err.values())),\n",
    "            alpha=0.1,\n",
    "        )\n",
    "\n",
    "    plt.ylabel('Normalized consumer utility')\n",
    "    plt.title(f\"Consumer and producer utility tradeoff for retrieving k=10 items ({groups_key.replace(\"group\", \"\").replace('_', ' ')} group)\")\n",
    "    plt.xlabel(r'Fraction of best min normalized item utility guaranteed, $\\gamma^I$')\n",
    "    plt.plot(GAMMA_POINTS, consumer_utils_mean, color=\"black\", label=\"Mean user utility\", linestyle=\"--\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{save_path}/tradeoff_curve_group_{groups_key}_n_consumers_{N_CONSUMERS}_n_producers_{N_PRODUCERS}_n_runs_{N_RUNS}_k_rec_{K_REC}_alpha_{ALPHA}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc850bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in GROUPS:\n",
    "    group_names = sorted({i[group] for i in GROUPS_MAP})\n",
    "\n",
    "    consumers_ids, consumers_utils = compute_consumer_producer_utils_per_gamma_for_groups(\n",
    "        rel_matrix=REL_MATRIX,\n",
    "        n_consumers=N_CONSUMERS,\n",
    "        n_producers=N_PRODUCERS,\n",
    "        n_runs=N_RUNS,\n",
    "        gamma_points=GAMMA_POINTS,\n",
    "        k_rec=K_REC,\n",
    "        groups_map=GROUPS_MAP,\n",
    "        group_key=group,\n",
    "        alpha=ALPHA\n",
    "    )\n",
    "\n",
    "    results, consumer_utils_mean = parse_results(consumers_ids, consumers_utils, N_RUNS, GAMMA_POINTS, group)\n",
    "    plot_groups_results(results, consumer_utils_mean, group, group_names, \"./media23\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-thesis",
   "language": "python",
   "name": "msc-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
